{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.initializers \n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilePath = \"/home/nramvinojen/Programs/Workbench/24Jan2019/\"\n",
    "NewFVlen = 100\n",
    "Class = 8\n",
    "#RunFolder = \"Default\"\n",
    "RunFolder = \"28Jan2019\"\n",
    "\n",
    "Class = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(FilePath + \"Runs/\"+ RunFolder + \"/FV100_fromResnet/Fixation_WeightedSum_Combined_Csv/TR_CombinedFixation_FeatureVector.csv\", header=None)\n",
    "X = dataframe.values.astype(float)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv(FilePath +\"Runs/\" + RunFolder + \"/FV2048_Resnet/TR_Label.csv\", header=None)\n",
    "Y_temp = dataframe.values\n",
    "Y = Y_temp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.keras.utils.to_categorical(Y, Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(FilePath + \"Runs/\"+ RunFolder + \"/FV100_fromResnet/Fixation_WeightedSum_Combined_Csv/Test_CombinedFixation_FeatureVector.csv\", header=None)\n",
    "X_test = dataframe.values.astype(float)\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(FilePath +\"Runs/\" + RunFolder + \"/FV2048_Resnet/Test_Label.csv\", header=None)\n",
    "Ytest_temp = dataframe.values\n",
    "Y_test = Ytest_temp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "encoded_Ytest = encoder.transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_one_hot = tf.keras.utils.to_categorical(Y_test, Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 28)                2828      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 8)                 232       \n",
      "=================================================================\n",
      "Total params: 3,060\n",
      "Trainable params: 3,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 240 samples, validate on 72 samples\n",
      "Epoch 1/1200\n",
      "240/240 [==============================]240/240 [==============================] - 3s 13ms/step - loss: 4.7282 - acc: 0.1417 - val_loss: 3.4332 - val_acc: 0.0694\n",
      "\n",
      "Epoch 2/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 4.6126 - acc: 0.1167 - val_loss: 3.3848 - val_acc: 0.0694\n",
      "\n",
      "Epoch 3/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 4.6542 - acc: 0.0875 - val_loss: 3.3281 - val_acc: 0.0694\n",
      "\n",
      "Epoch 4/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 4.3867 - acc: 0.0833 - val_loss: 3.2754 - val_acc: 0.0694\n",
      "\n",
      "Epoch 5/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 69us/step - loss: 4.3814 - acc: 0.0667 - val_loss: 3.2205 - val_acc: 0.0694\n",
      "\n",
      "Epoch 6/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 4.1735 - acc: 0.1208 - val_loss: 3.1687 - val_acc: 0.0833\n",
      "\n",
      "Epoch 7/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 3.9810 - acc: 0.0958 - val_loss: 3.1365 - val_acc: 0.0833\n",
      "\n",
      "Epoch 8/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 4.1108 - acc: 0.1375 - val_loss: 3.0933 - val_acc: 0.0833\n",
      "\n",
      "Epoch 9/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 3.8483 - acc: 0.0875 - val_loss: 3.0497 - val_acc: 0.0833\n",
      "\n",
      "Epoch 10/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 3.8892 - acc: 0.1208 - val_loss: 3.0141 - val_acc: 0.0556\n",
      "\n",
      "Epoch 11/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 3.8256 - acc: 0.1125 - val_loss: 2.9640 - val_acc: 0.0417\n",
      "\n",
      "Epoch 12/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 3.8759 - acc: 0.1375 - val_loss: 2.9221 - val_acc: 0.0278\n",
      "\n",
      "Epoch 13/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 3.6378 - acc: 0.1333 - val_loss: 2.8860 - val_acc: 0.0417\n",
      "\n",
      "Epoch 14/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 3.5113 - acc: 0.1042 - val_loss: 2.8566 - val_acc: 0.0417\n",
      "\n",
      "Epoch 15/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 3.5344 - acc: 0.1458 - val_loss: 2.8230 - val_acc: 0.0417\n",
      "\n",
      "Epoch 16/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 43us/step - loss: 3.5840 - acc: 0.0958 - val_loss: 2.7913 - val_acc: 0.0417\n",
      "\n",
      "Epoch 17/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 3.3924 - acc: 0.1375 - val_loss: 2.7627 - val_acc: 0.0417\n",
      "\n",
      "Epoch 18/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 3.4405 - acc: 0.1458 - val_loss: 2.7377 - val_acc: 0.0417\n",
      "\n",
      "Epoch 19/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 3.3129 - acc: 0.1250 - val_loss: 2.7115 - val_acc: 0.0417\n",
      "\n",
      "Epoch 20/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 3.3377 - acc: 0.1500 - val_loss: 2.6866 - val_acc: 0.0417\n",
      "\n",
      "Epoch 21/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 126us/step - loss: 3.3057 - acc: 0.1167 - val_loss: 2.6511 - val_acc: 0.0417\n",
      "\n",
      "Epoch 22/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 3.1001 - acc: 0.1625 - val_loss: 2.6190 - val_acc: 0.0556\n",
      "\n",
      "Epoch 23/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 3.4172 - acc: 0.0875 - val_loss: 2.5943 - val_acc: 0.0417\n",
      "\n",
      "Epoch 24/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 3.1540 - acc: 0.1375 - val_loss: 2.5728 - val_acc: 0.0417\n",
      "\n",
      "Epoch 25/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 3.0764 - acc: 0.0875 - val_loss: 2.5504 - val_acc: 0.0556\n",
      "\n",
      "Epoch 26/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 3.0753 - acc: 0.1125 - val_loss: 2.5289 - val_acc: 0.0417\n",
      "\n",
      "Epoch 27/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 2.8293 - acc: 0.1500 - val_loss: 2.5045 - val_acc: 0.0417\n",
      "\n",
      "Epoch 28/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 2.7557 - acc: 0.1417 - val_loss: 2.4833 - val_acc: 0.0417\n",
      "\n",
      "Epoch 29/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 2.9577 - acc: 0.1250 - val_loss: 2.4613 - val_acc: 0.0417\n",
      "\n",
      "Epoch 30/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 2.9337 - acc: 0.1250 - val_loss: 2.4377 - val_acc: 0.0417\n",
      "\n",
      "Epoch 31/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 2.7899 - acc: 0.1667 - val_loss: 2.4151 - val_acc: 0.0278\n",
      "\n",
      "Epoch 32/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 2.7432 - acc: 0.1458 - val_loss: 2.3968 - val_acc: 0.0278\n",
      "\n",
      "Epoch 33/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 2.7116 - acc: 0.1292 - val_loss: 2.3737 - val_acc: 0.0278\n",
      "\n",
      "Epoch 34/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 2.6145 - acc: 0.1375 - val_loss: 2.3521 - val_acc: 0.0278\n",
      "\n",
      "Epoch 35/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 2.6293 - acc: 0.1083 - val_loss: 2.3295 - val_acc: 0.0278\n",
      "\n",
      "Epoch 36/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 2.6269 - acc: 0.1250 - val_loss: 2.3088 - val_acc: 0.0278\n",
      "\n",
      "Epoch 37/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 2.6374 - acc: 0.1583 - val_loss: 2.2921 - val_acc: 0.0278\n",
      "\n",
      "Epoch 38/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 2.4637 - acc: 0.1708 - val_loss: 2.2770 - val_acc: 0.0278\n",
      "\n",
      "Epoch 39/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 2.6137 - acc: 0.1375 - val_loss: 2.2665 - val_acc: 0.0556\n",
      "\n",
      "Epoch 40/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 2.4595 - acc: 0.1417 - val_loss: 2.2499 - val_acc: 0.0694\n",
      "\n",
      "Epoch 41/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 2.5154 - acc: 0.1708 - val_loss: 2.2327 - val_acc: 0.0694\n",
      "\n",
      "Epoch 42/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 2.4077 - acc: 0.1583 - val_loss: 2.2229 - val_acc: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 2.4485 - acc: 0.1333 - val_loss: 2.2130 - val_acc: 0.0833\n",
      "\n",
      "Epoch 44/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 2.4667 - acc: 0.1417 - val_loss: 2.2020 - val_acc: 0.0972\n",
      "\n",
      "Epoch 45/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 2.3501 - acc: 0.1750 - val_loss: 2.1872 - val_acc: 0.0972\n",
      "\n",
      "Epoch 46/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 2.3179 - acc: 0.1667 - val_loss: 2.1810 - val_acc: 0.1111\n",
      "\n",
      "Epoch 47/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 2.3754 - acc: 0.1708 - val_loss: 2.1657 - val_acc: 0.1389\n",
      "\n",
      "Epoch 48/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 2.2954 - acc: 0.1500 - val_loss: 2.1616 - val_acc: 0.1111\n",
      "\n",
      "Epoch 49/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 2.1839 - acc: 0.2042 - val_loss: 2.1506 - val_acc: 0.1389\n",
      "\n",
      "Epoch 50/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 2.2896 - acc: 0.1750 - val_loss: 2.1359 - val_acc: 0.1667\n",
      "\n",
      "Epoch 51/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 2.3701 - acc: 0.1708 - val_loss: 2.1324 - val_acc: 0.1389\n",
      "\n",
      "Epoch 52/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 2.1940 - acc: 0.1833 - val_loss: 2.1204 - val_acc: 0.1667\n",
      "\n",
      "Epoch 53/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 2.2008 - acc: 0.2292 - val_loss: 2.1110 - val_acc: 0.1667\n",
      "\n",
      "Epoch 54/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 2.1926 - acc: 0.2000 - val_loss: 2.1088 - val_acc: 0.1806\n",
      "\n",
      "Epoch 55/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 2.2333 - acc: 0.2417 - val_loss: 2.0945 - val_acc: 0.1944\n",
      "\n",
      "Epoch 56/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 2.1932 - acc: 0.2250 - val_loss: 2.0879 - val_acc: 0.2083\n",
      "\n",
      "Epoch 57/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 2.2034 - acc: 0.1625 - val_loss: 2.0809 - val_acc: 0.2083\n",
      "\n",
      "Epoch 58/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 2.1385 - acc: 0.2000 - val_loss: 2.0724 - val_acc: 0.2083\n",
      "\n",
      "Epoch 59/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 2.2264 - acc: 0.2042 - val_loss: 2.0676 - val_acc: 0.2083\n",
      "\n",
      "Epoch 60/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 2.2405 - acc: 0.1708 - val_loss: 2.0650 - val_acc: 0.2222\n",
      "\n",
      "Epoch 61/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 2.1024 - acc: 0.1958 - val_loss: 2.0579 - val_acc: 0.2500\n",
      "\n",
      "Epoch 62/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 2.1286 - acc: 0.2292 - val_loss: 2.0519 - val_acc: 0.2361\n",
      "\n",
      "Epoch 63/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 2.0576 - acc: 0.2042 - val_loss: 2.0475 - val_acc: 0.2361\n",
      "\n",
      "Epoch 64/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.9762 - acc: 0.2542 - val_loss: 2.0413 - val_acc: 0.2361\n",
      "\n",
      "Epoch 65/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 2.1434 - acc: 0.2000 - val_loss: 2.0386 - val_acc: 0.2361\n",
      "\n",
      "Epoch 66/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 2.0454 - acc: 0.2250 - val_loss: 2.0338 - val_acc: 0.2361\n",
      "\n",
      "Epoch 67/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 2.0961 - acc: 0.2375 - val_loss: 2.0263 - val_acc: 0.2500\n",
      "\n",
      "Epoch 68/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 2.0692 - acc: 0.2375 - val_loss: 2.0233 - val_acc: 0.2361\n",
      "\n",
      "Epoch 69/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 2.0813 - acc: 0.1958 - val_loss: 2.0200 - val_acc: 0.2222\n",
      "\n",
      "Epoch 70/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 2.0316 - acc: 0.2750 - val_loss: 2.0180 - val_acc: 0.2222\n",
      "\n",
      "Epoch 71/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 2.0573 - acc: 0.2250 - val_loss: 2.0136 - val_acc: 0.2222\n",
      "\n",
      "Epoch 72/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 2.0570 - acc: 0.2000 - val_loss: 2.0130 - val_acc: 0.2083\n",
      "\n",
      "Epoch 73/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.9970 - acc: 0.2417 - val_loss: 2.0087 - val_acc: 0.2222\n",
      "\n",
      "Epoch 74/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 2.0483 - acc: 0.2333 - val_loss: 2.0042 - val_acc: 0.2222\n",
      "\n",
      "Epoch 75/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 2.0188 - acc: 0.2500 - val_loss: 2.0039 - val_acc: 0.2222\n",
      "\n",
      "Epoch 76/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 2.0183 - acc: 0.2000 - val_loss: 1.9967 - val_acc: 0.2500\n",
      "\n",
      "Epoch 77/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 2.0491 - acc: 0.2333 - val_loss: 1.9946 - val_acc: 0.2500\n",
      "\n",
      "Epoch 78/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.8998 - acc: 0.2667 - val_loss: 1.9935 - val_acc: 0.2500\n",
      "\n",
      "Epoch 79/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 2.0684 - acc: 0.1875 - val_loss: 1.9898 - val_acc: 0.2639\n",
      "\n",
      "Epoch 80/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.9860 - acc: 0.2375 - val_loss: 1.9895 - val_acc: 0.2778\n",
      "\n",
      "Epoch 81/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.9867 - acc: 0.2458 - val_loss: 1.9808 - val_acc: 0.2917\n",
      "\n",
      "Epoch 82/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.9942 - acc: 0.2042 - val_loss: 1.9802 - val_acc: 0.2778\n",
      "\n",
      "Epoch 83/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.9403 - acc: 0.2667 - val_loss: 1.9747 - val_acc: 0.2917\n",
      "\n",
      "Epoch 84/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.9989 - acc: 0.2375 - val_loss: 1.9775 - val_acc: 0.2778\n",
      "\n",
      "Epoch 85/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.9674 - acc: 0.2417 - val_loss: 1.9693 - val_acc: 0.3056\n",
      "\n",
      "Epoch 86/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.8964 - acc: 0.3167 - val_loss: 1.9636 - val_acc: 0.3194\n",
      "\n",
      "Epoch 87/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 2.0113 - acc: 0.2292 - val_loss: 1.9627 - val_acc: 0.3194\n",
      "\n",
      "Epoch 88/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.9279 - acc: 0.2750 - val_loss: 1.9607 - val_acc: 0.3333\n",
      "\n",
      "Epoch 89/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.9503 - acc: 0.2458 - val_loss: 1.9600 - val_acc: 0.3194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.8976 - acc: 0.2375 - val_loss: 1.9567 - val_acc: 0.3472\n",
      "\n",
      "Epoch 91/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 112us/step - loss: 1.9866 - acc: 0.2458 - val_loss: 1.9567 - val_acc: 0.3194\n",
      "\n",
      "Epoch 92/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.9317 - acc: 0.3083 - val_loss: 1.9507 - val_acc: 0.3472\n",
      "\n",
      "Epoch 93/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 106us/step - loss: 1.9475 - acc: 0.2750 - val_loss: 1.9477 - val_acc: 0.3472\n",
      "\n",
      "Epoch 94/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.8546 - acc: 0.2500 - val_loss: 1.9463 - val_acc: 0.3472\n",
      "\n",
      "Epoch 95/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 112us/step - loss: 1.9028 - acc: 0.2792 - val_loss: 1.9472 - val_acc: 0.3333\n",
      "\n",
      "Epoch 96/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.9375 - acc: 0.2333 - val_loss: 1.9432 - val_acc: 0.3333\n",
      "\n",
      "Epoch 97/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.8699 - acc: 0.2708 - val_loss: 1.9377 - val_acc: 0.3472\n",
      "\n",
      "Epoch 98/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.8764 - acc: 0.3042 - val_loss: 1.9367 - val_acc: 0.3472\n",
      "\n",
      "Epoch 99/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.9409 - acc: 0.2542 - val_loss: 1.9352 - val_acc: 0.3472\n",
      "\n",
      "Epoch 100/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.8962 - acc: 0.2750 - val_loss: 1.9338 - val_acc: 0.3472\n",
      "\n",
      "Epoch 101/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.8468 - acc: 0.2875 - val_loss: 1.9281 - val_acc: 0.3889\n",
      "\n",
      "Epoch 102/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.8554 - acc: 0.3083 - val_loss: 1.9238 - val_acc: 0.3889\n",
      "\n",
      "Epoch 103/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.8547 - acc: 0.2667 - val_loss: 1.9233 - val_acc: 0.3750\n",
      "\n",
      "Epoch 104/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.8025 - acc: 0.3125 - val_loss: 1.9208 - val_acc: 0.3889\n",
      "\n",
      "Epoch 105/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.8885 - acc: 0.2708 - val_loss: 1.9213 - val_acc: 0.3889\n",
      "\n",
      "Epoch 106/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.8910 - acc: 0.2542 - val_loss: 1.9193 - val_acc: 0.3889\n",
      "\n",
      "Epoch 107/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.8547 - acc: 0.2583 - val_loss: 1.9201 - val_acc: 0.3750\n",
      "\n",
      "Epoch 108/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.8149 - acc: 0.3333 - val_loss: 1.9204 - val_acc: 0.3611\n",
      "\n",
      "Epoch 109/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.8597 - acc: 0.3083 - val_loss: 1.9174 - val_acc: 0.3750\n",
      "\n",
      "Epoch 110/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.8462 - acc: 0.2958 - val_loss: 1.9161 - val_acc: 0.3889\n",
      "\n",
      "Epoch 111/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.8669 - acc: 0.3125 - val_loss: 1.9137 - val_acc: 0.3889\n",
      "\n",
      "Epoch 112/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.8810 - acc: 0.2750 - val_loss: 1.9111 - val_acc: 0.3889\n",
      "\n",
      "Epoch 113/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.8516 - acc: 0.3042 - val_loss: 1.9085 - val_acc: 0.4028\n",
      "\n",
      "Epoch 114/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.8998 - acc: 0.2750 - val_loss: 1.9087 - val_acc: 0.3889\n",
      "\n",
      "Epoch 115/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.7668 - acc: 0.3208 - val_loss: 1.9080 - val_acc: 0.3889\n",
      "\n",
      "Epoch 116/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.7141 - acc: 0.3875 - val_loss: 1.9061 - val_acc: 0.3889\n",
      "\n",
      "Epoch 117/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.8600 - acc: 0.3292 - val_loss: 1.9049 - val_acc: 0.4028\n",
      "\n",
      "Epoch 118/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.8896 - acc: 0.2875 - val_loss: 1.9020 - val_acc: 0.4028\n",
      "\n",
      "Epoch 119/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.8531 - acc: 0.2833 - val_loss: 1.8982 - val_acc: 0.3889\n",
      "\n",
      "Epoch 120/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 139us/step - loss: 1.8375 - acc: 0.2958 - val_loss: 1.8936 - val_acc: 0.4028\n",
      "\n",
      "Epoch 121/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 125us/step - loss: 1.8186 - acc: 0.3417 - val_loss: 1.8888 - val_acc: 0.4028\n",
      "\n",
      "Epoch 122/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.7752 - acc: 0.3375 - val_loss: 1.8872 - val_acc: 0.3889\n",
      "\n",
      "Epoch 123/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.7987 - acc: 0.3083 - val_loss: 1.8850 - val_acc: 0.3889\n",
      "\n",
      "Epoch 124/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.7815 - acc: 0.3292 - val_loss: 1.8818 - val_acc: 0.3889\n",
      "\n",
      "Epoch 125/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.7912 - acc: 0.3042 - val_loss: 1.8806 - val_acc: 0.3750\n",
      "\n",
      "Epoch 126/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.8194 - acc: 0.2833 - val_loss: 1.8798 - val_acc: 0.3889\n",
      "\n",
      "Epoch 127/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 131us/step - loss: 1.7330 - acc: 0.3875 - val_loss: 1.8752 - val_acc: 0.3611\n",
      "\n",
      "Epoch 128/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.8032 - acc: 0.3000 - val_loss: 1.8769 - val_acc: 0.3750\n",
      "\n",
      "Epoch 129/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.7630 - acc: 0.3250 - val_loss: 1.8771 - val_acc: 0.3611\n",
      "\n",
      "Epoch 130/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.8205 - acc: 0.3167 - val_loss: 1.8817 - val_acc: 0.3750\n",
      "\n",
      "Epoch 131/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.7458 - acc: 0.3250 - val_loss: 1.8783 - val_acc: 0.4028\n",
      "\n",
      "Epoch 132/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.8377 - acc: 0.3000 - val_loss: 1.8782 - val_acc: 0.4028\n",
      "\n",
      "Epoch 133/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.7826 - acc: 0.3167 - val_loss: 1.8765 - val_acc: 0.3889\n",
      "\n",
      "Epoch 134/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.7940 - acc: 0.3500 - val_loss: 1.8715 - val_acc: 0.3889\n",
      "\n",
      "Epoch 135/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.7784 - acc: 0.3583 - val_loss: 1.8671 - val_acc: 0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.7520 - acc: 0.3208 - val_loss: 1.8656 - val_acc: 0.3750\n",
      "\n",
      "Epoch 137/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.7452 - acc: 0.3750 - val_loss: 1.8620 - val_acc: 0.3889\n",
      "\n",
      "Epoch 138/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.7854 - acc: 0.3542 - val_loss: 1.8622 - val_acc: 0.3889\n",
      "\n",
      "Epoch 139/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.7036 - acc: 0.3667 - val_loss: 1.8594 - val_acc: 0.3889\n",
      "\n",
      "Epoch 140/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.7057 - acc: 0.3583 - val_loss: 1.8574 - val_acc: 0.3750\n",
      "\n",
      "Epoch 141/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.7242 - acc: 0.3333 - val_loss: 1.8559 - val_acc: 0.3889\n",
      "\n",
      "Epoch 142/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.7923 - acc: 0.3208 - val_loss: 1.8544 - val_acc: 0.3889\n",
      "\n",
      "Epoch 143/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.8461 - acc: 0.3417 - val_loss: 1.8543 - val_acc: 0.3750\n",
      "\n",
      "Epoch 144/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.7313 - acc: 0.3500 - val_loss: 1.8496 - val_acc: 0.4028\n",
      "\n",
      "Epoch 145/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.7558 - acc: 0.3167 - val_loss: 1.8493 - val_acc: 0.4028\n",
      "\n",
      "Epoch 146/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 52us/step - loss: 1.8028 - acc: 0.3500 - val_loss: 1.8484 - val_acc: 0.4028\n",
      "\n",
      "Epoch 147/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 57us/step - loss: 1.7264 - acc: 0.3458 - val_loss: 1.8489 - val_acc: 0.4028\n",
      "\n",
      "Epoch 148/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 40us/step - loss: 1.7527 - acc: 0.3250 - val_loss: 1.8469 - val_acc: 0.3889\n",
      "\n",
      "Epoch 149/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 42us/step - loss: 1.7253 - acc: 0.3542 - val_loss: 1.8438 - val_acc: 0.4028\n",
      "\n",
      "Epoch 150/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.7312 - acc: 0.3458 - val_loss: 1.8406 - val_acc: 0.3889\n",
      "\n",
      "Epoch 151/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 62us/step - loss: 1.7151 - acc: 0.3333 - val_loss: 1.8402 - val_acc: 0.3889\n",
      "\n",
      "Epoch 152/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.7638 - acc: 0.3875 - val_loss: 1.8364 - val_acc: 0.3889\n",
      "\n",
      "Epoch 153/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.7135 - acc: 0.3375 - val_loss: 1.8398 - val_acc: 0.4028\n",
      "\n",
      "Epoch 154/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.7871 - acc: 0.3458 - val_loss: 1.8408 - val_acc: 0.3889\n",
      "\n",
      "Epoch 155/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.7742 - acc: 0.3458 - val_loss: 1.8391 - val_acc: 0.4028\n",
      "\n",
      "Epoch 156/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.7822 - acc: 0.3458 - val_loss: 1.8394 - val_acc: 0.4167\n",
      "\n",
      "Epoch 157/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.7602 - acc: 0.3500 - val_loss: 1.8403 - val_acc: 0.4167\n",
      "\n",
      "Epoch 158/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.7494 - acc: 0.3125 - val_loss: 1.8367 - val_acc: 0.3889\n",
      "\n",
      "Epoch 159/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.7263 - acc: 0.3583 - val_loss: 1.8345 - val_acc: 0.4028\n",
      "\n",
      "Epoch 160/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.7430 - acc: 0.3792 - val_loss: 1.8362 - val_acc: 0.3889\n",
      "\n",
      "Epoch 161/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.7034 - acc: 0.4375 - val_loss: 1.8319 - val_acc: 0.3889\n",
      "\n",
      "Epoch 162/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.6802 - acc: 0.4083 - val_loss: 1.8289 - val_acc: 0.3889\n",
      "\n",
      "Epoch 163/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.7283 - acc: 0.3625 - val_loss: 1.8263 - val_acc: 0.4028\n",
      "\n",
      "Epoch 164/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.7771 - acc: 0.3375 - val_loss: 1.8253 - val_acc: 0.4167\n",
      "\n",
      "Epoch 165/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.7315 - acc: 0.3500 - val_loss: 1.8202 - val_acc: 0.4306\n",
      "\n",
      "Epoch 166/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.7222 - acc: 0.3750 - val_loss: 1.8189 - val_acc: 0.4167\n",
      "\n",
      "Epoch 167/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.7384 - acc: 0.3750 - val_loss: 1.8209 - val_acc: 0.4167\n",
      "\n",
      "Epoch 168/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.7038 - acc: 0.4000 - val_loss: 1.8185 - val_acc: 0.4167\n",
      "\n",
      "Epoch 169/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.6746 - acc: 0.3792 - val_loss: 1.8167 - val_acc: 0.4028\n",
      "\n",
      "Epoch 170/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.6778 - acc: 0.3958 - val_loss: 1.8137 - val_acc: 0.4306\n",
      "\n",
      "Epoch 171/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.6738 - acc: 0.4083 - val_loss: 1.8112 - val_acc: 0.4167\n",
      "\n",
      "Epoch 172/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.7145 - acc: 0.3792 - val_loss: 1.8122 - val_acc: 0.4167\n",
      "\n",
      "Epoch 173/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.7131 - acc: 0.3500 - val_loss: 1.8098 - val_acc: 0.4028\n",
      "\n",
      "Epoch 174/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.7177 - acc: 0.3708 - val_loss: 1.8106 - val_acc: 0.4028\n",
      "\n",
      "Epoch 175/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 69us/step - loss: 1.6953 - acc: 0.3917 - val_loss: 1.8105 - val_acc: 0.4167\n",
      "\n",
      "Epoch 176/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.6723 - acc: 0.4083 - val_loss: 1.8083 - val_acc: 0.4306\n",
      "\n",
      "Epoch 177/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.7031 - acc: 0.4292 - val_loss: 1.8070 - val_acc: 0.4167\n",
      "\n",
      "Epoch 178/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.7145 - acc: 0.3458 - val_loss: 1.8055 - val_acc: 0.4167\n",
      "\n",
      "Epoch 179/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 38us/step - loss: 1.6817 - acc: 0.3792 - val_loss: 1.8043 - val_acc: 0.4167\n",
      "\n",
      "Epoch 180/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 43us/step - loss: 1.6799 - acc: 0.3917 - val_loss: 1.8011 - val_acc: 0.4167\n",
      "\n",
      "Epoch 181/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 39us/step - loss: 1.6895 - acc: 0.3500 - val_loss: 1.8015 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 182/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.7229 - acc: 0.3833 - val_loss: 1.8005 - val_acc: 0.4167\n",
      "\n",
      "Epoch 183/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.6912 - acc: 0.3792 - val_loss: 1.8013 - val_acc: 0.4167\n",
      "\n",
      "Epoch 184/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.6725 - acc: 0.4292 - val_loss: 1.8009 - val_acc: 0.4306\n",
      "\n",
      "Epoch 185/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.7361 - acc: 0.3667 - val_loss: 1.8002 - val_acc: 0.4167\n",
      "\n",
      "Epoch 186/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.6909 - acc: 0.4042 - val_loss: 1.7982 - val_acc: 0.4167\n",
      "\n",
      "Epoch 187/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 1.7088 - acc: 0.3708 - val_loss: 1.7961 - val_acc: 0.4306\n",
      "\n",
      "Epoch 188/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.6740 - acc: 0.4000 - val_loss: 1.7946 - val_acc: 0.4306\n",
      "\n",
      "Epoch 189/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.6645 - acc: 0.3708 - val_loss: 1.7936 - val_acc: 0.4028\n",
      "\n",
      "Epoch 190/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.6626 - acc: 0.4042 - val_loss: 1.7929 - val_acc: 0.4167\n",
      "\n",
      "Epoch 191/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.6135 - acc: 0.4083 - val_loss: 1.7933 - val_acc: 0.4167\n",
      "\n",
      "Epoch 192/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.7043 - acc: 0.3667 - val_loss: 1.7921 - val_acc: 0.4167\n",
      "\n",
      "Epoch 193/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.6760 - acc: 0.3750 - val_loss: 1.7928 - val_acc: 0.4167\n",
      "\n",
      "Epoch 194/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.6922 - acc: 0.3667 - val_loss: 1.7920 - val_acc: 0.4167\n",
      "\n",
      "Epoch 195/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.6593 - acc: 0.4333 - val_loss: 1.7927 - val_acc: 0.4167\n",
      "\n",
      "Epoch 196/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.6637 - acc: 0.3583 - val_loss: 1.7937 - val_acc: 0.4167\n",
      "\n",
      "Epoch 197/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.6896 - acc: 0.3375 - val_loss: 1.7914 - val_acc: 0.4167\n",
      "\n",
      "Epoch 198/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 112us/step - loss: 1.6968 - acc: 0.3833 - val_loss: 1.7923 - val_acc: 0.4167\n",
      "\n",
      "Epoch 199/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.6651 - acc: 0.4083 - val_loss: 1.7895 - val_acc: 0.4167\n",
      "\n",
      "Epoch 200/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.6956 - acc: 0.3875 - val_loss: 1.7861 - val_acc: 0.4167\n",
      "\n",
      "Epoch 201/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.6870 - acc: 0.4083 - val_loss: 1.7846 - val_acc: 0.4167\n",
      "\n",
      "Epoch 202/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 112us/step - loss: 1.6698 - acc: 0.3750 - val_loss: 1.7849 - val_acc: 0.4167\n",
      "\n",
      "Epoch 203/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.6699 - acc: 0.4125 - val_loss: 1.7851 - val_acc: 0.4167\n",
      "\n",
      "Epoch 204/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.6533 - acc: 0.4208 - val_loss: 1.7821 - val_acc: 0.4306\n",
      "\n",
      "Epoch 205/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.6444 - acc: 0.4167 - val_loss: 1.7804 - val_acc: 0.4167\n",
      "\n",
      "Epoch 206/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.6705 - acc: 0.3708 - val_loss: 1.7791 - val_acc: 0.4306\n",
      "\n",
      "Epoch 207/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.6886 - acc: 0.4000 - val_loss: 1.7757 - val_acc: 0.4167\n",
      "\n",
      "Epoch 208/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.6405 - acc: 0.3792 - val_loss: 1.7758 - val_acc: 0.4444\n",
      "\n",
      "Epoch 209/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.6600 - acc: 0.4208 - val_loss: 1.7748 - val_acc: 0.4306\n",
      "\n",
      "Epoch 210/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 1.6618 - acc: 0.4292 - val_loss: 1.7731 - val_acc: 0.4306\n",
      "\n",
      "Epoch 211/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.6136 - acc: 0.3917 - val_loss: 1.7707 - val_acc: 0.4444\n",
      "\n",
      "Epoch 212/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.6049 - acc: 0.4083 - val_loss: 1.7691 - val_acc: 0.4444\n",
      "\n",
      "Epoch 213/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 43us/step - loss: 1.6124 - acc: 0.4000 - val_loss: 1.7685 - val_acc: 0.4444\n",
      "\n",
      "Epoch 214/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.6308 - acc: 0.3958 - val_loss: 1.7680 - val_acc: 0.4444\n",
      "\n",
      "Epoch 215/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.6579 - acc: 0.4500 - val_loss: 1.7697 - val_acc: 0.4444\n",
      "\n",
      "Epoch 216/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.6202 - acc: 0.4167 - val_loss: 1.7691 - val_acc: 0.4444\n",
      "\n",
      "Epoch 217/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.7054 - acc: 0.3875 - val_loss: 1.7682 - val_acc: 0.4444\n",
      "\n",
      "Epoch 218/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 66us/step - loss: 1.6379 - acc: 0.4250 - val_loss: 1.7664 - val_acc: 0.4444\n",
      "\n",
      "Epoch 219/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.6398 - acc: 0.4208 - val_loss: 1.7679 - val_acc: 0.4306\n",
      "\n",
      "Epoch 220/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.6754 - acc: 0.3833 - val_loss: 1.7687 - val_acc: 0.4444\n",
      "\n",
      "Epoch 221/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.5994 - acc: 0.4292 - val_loss: 1.7690 - val_acc: 0.4444\n",
      "\n",
      "Epoch 222/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.5994 - acc: 0.4500 - val_loss: 1.7695 - val_acc: 0.4444\n",
      "\n",
      "Epoch 223/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.6851 - acc: 0.3750 - val_loss: 1.7680 - val_acc: 0.4444\n",
      "\n",
      "Epoch 224/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.6712 - acc: 0.4000 - val_loss: 1.7674 - val_acc: 0.4444\n",
      "\n",
      "Epoch 225/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.6396 - acc: 0.4083 - val_loss: 1.7691 - val_acc: 0.4444\n",
      "\n",
      "Epoch 226/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 126us/step - loss: 1.6815 - acc: 0.3708 - val_loss: 1.7687 - val_acc: 0.4306\n",
      "\n",
      "Epoch 227/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 1.6208 - acc: 0.3958 - val_loss: 1.7662 - val_acc: 0.4028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 228/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.6390 - acc: 0.4333 - val_loss: 1.7635 - val_acc: 0.4306\n",
      "\n",
      "Epoch 229/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.6663 - acc: 0.3833 - val_loss: 1.7623 - val_acc: 0.4444\n",
      "\n",
      "Epoch 230/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.6288 - acc: 0.4125 - val_loss: 1.7637 - val_acc: 0.4444\n",
      "\n",
      "Epoch 231/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.6104 - acc: 0.4250 - val_loss: 1.7634 - val_acc: 0.4444\n",
      "\n",
      "Epoch 232/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.6315 - acc: 0.4125 - val_loss: 1.7648 - val_acc: 0.4306\n",
      "\n",
      "Epoch 233/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.5486 - acc: 0.4583 - val_loss: 1.7647 - val_acc: 0.4444\n",
      "\n",
      "Epoch 234/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.6537 - acc: 0.3625 - val_loss: 1.7632 - val_acc: 0.4306\n",
      "\n",
      "Epoch 235/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.6416 - acc: 0.3875 - val_loss: 1.7661 - val_acc: 0.4306\n",
      "\n",
      "Epoch 236/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.6334 - acc: 0.4292 - val_loss: 1.7663 - val_acc: 0.4306\n",
      "\n",
      "Epoch 237/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5888 - acc: 0.4292 - val_loss: 1.7625 - val_acc: 0.4167\n",
      "\n",
      "Epoch 238/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.5951 - acc: 0.4000 - val_loss: 1.7637 - val_acc: 0.4167\n",
      "\n",
      "Epoch 239/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.6363 - acc: 0.3875 - val_loss: 1.7628 - val_acc: 0.4306\n",
      "\n",
      "Epoch 240/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.6499 - acc: 0.4000 - val_loss: 1.7627 - val_acc: 0.4306\n",
      "\n",
      "Epoch 241/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.6054 - acc: 0.4042 - val_loss: 1.7634 - val_acc: 0.4444\n",
      "\n",
      "Epoch 242/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.6497 - acc: 0.3750 - val_loss: 1.7649 - val_acc: 0.4306\n",
      "\n",
      "Epoch 243/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.6275 - acc: 0.4042 - val_loss: 1.7645 - val_acc: 0.4444\n",
      "\n",
      "Epoch 244/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.6327 - acc: 0.4125 - val_loss: 1.7631 - val_acc: 0.4444\n",
      "\n",
      "Epoch 245/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.5773 - acc: 0.4208 - val_loss: 1.7602 - val_acc: 0.4444\n",
      "\n",
      "Epoch 246/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 52us/step - loss: 1.6061 - acc: 0.4292 - val_loss: 1.7579 - val_acc: 0.4306\n",
      "\n",
      "Epoch 247/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.6024 - acc: 0.4208 - val_loss: 1.7568 - val_acc: 0.4444\n",
      "\n",
      "Epoch 248/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.5939 - acc: 0.4042 - val_loss: 1.7588 - val_acc: 0.4444\n",
      "\n",
      "Epoch 249/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.6508 - acc: 0.4125 - val_loss: 1.7561 - val_acc: 0.4444\n",
      "\n",
      "Epoch 250/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.6034 - acc: 0.4042 - val_loss: 1.7577 - val_acc: 0.4306\n",
      "\n",
      "Epoch 251/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.6190 - acc: 0.4250 - val_loss: 1.7570 - val_acc: 0.4444\n",
      "\n",
      "Epoch 252/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 1.6199 - acc: 0.4167 - val_loss: 1.7568 - val_acc: 0.4444\n",
      "\n",
      "Epoch 253/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.6771 - acc: 0.4000 - val_loss: 1.7555 - val_acc: 0.4306\n",
      "\n",
      "Epoch 254/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.5740 - acc: 0.4125 - val_loss: 1.7549 - val_acc: 0.4306\n",
      "\n",
      "Epoch 255/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 126us/step - loss: 1.5804 - acc: 0.4375 - val_loss: 1.7518 - val_acc: 0.4306\n",
      "\n",
      "Epoch 256/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.5892 - acc: 0.4083 - val_loss: 1.7520 - val_acc: 0.4444\n",
      "\n",
      "Epoch 257/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.6094 - acc: 0.4208 - val_loss: 1.7548 - val_acc: 0.4444\n",
      "\n",
      "Epoch 258/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.5872 - acc: 0.4208 - val_loss: 1.7558 - val_acc: 0.4444\n",
      "\n",
      "Epoch 259/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.5521 - acc: 0.4208 - val_loss: 1.7563 - val_acc: 0.4444\n",
      "\n",
      "Epoch 260/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.6313 - acc: 0.4125 - val_loss: 1.7526 - val_acc: 0.4306\n",
      "\n",
      "Epoch 261/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.5962 - acc: 0.4167 - val_loss: 1.7511 - val_acc: 0.4444\n",
      "\n",
      "Epoch 262/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.6220 - acc: 0.4167 - val_loss: 1.7517 - val_acc: 0.4306\n",
      "\n",
      "Epoch 263/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.6104 - acc: 0.4000 - val_loss: 1.7481 - val_acc: 0.4306\n",
      "\n",
      "Epoch 264/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.6272 - acc: 0.3958 - val_loss: 1.7472 - val_acc: 0.4306\n",
      "\n",
      "Epoch 265/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 128us/step - loss: 1.5895 - acc: 0.4333 - val_loss: 1.7476 - val_acc: 0.4306\n",
      "\n",
      "Epoch 266/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.5898 - acc: 0.4292 - val_loss: 1.7462 - val_acc: 0.4028\n",
      "\n",
      "Epoch 267/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.6335 - acc: 0.4000 - val_loss: 1.7464 - val_acc: 0.4167\n",
      "\n",
      "Epoch 268/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.5324 - acc: 0.4500 - val_loss: 1.7451 - val_acc: 0.4306\n",
      "\n",
      "Epoch 269/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.5780 - acc: 0.4417 - val_loss: 1.7451 - val_acc: 0.4306\n",
      "\n",
      "Epoch 270/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.5775 - acc: 0.4167 - val_loss: 1.7433 - val_acc: 0.4167\n",
      "\n",
      "Epoch 271/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.6168 - acc: 0.4458 - val_loss: 1.7457 - val_acc: 0.4306\n",
      "\n",
      "Epoch 272/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.5932 - acc: 0.4250 - val_loss: 1.7425 - val_acc: 0.4306\n",
      "\n",
      "Epoch 273/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.5604 - acc: 0.4542 - val_loss: 1.7413 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 274/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 69us/step - loss: 1.5869 - acc: 0.4083 - val_loss: 1.7403 - val_acc: 0.4306\n",
      "\n",
      "Epoch 275/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.6260 - acc: 0.4292 - val_loss: 1.7408 - val_acc: 0.4306\n",
      "\n",
      "Epoch 276/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.6077 - acc: 0.4417 - val_loss: 1.7421 - val_acc: 0.4444\n",
      "\n",
      "Epoch 277/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.5768 - acc: 0.4167 - val_loss: 1.7413 - val_acc: 0.4306\n",
      "\n",
      "Epoch 278/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.6030 - acc: 0.4167 - val_loss: 1.7439 - val_acc: 0.4444\n",
      "\n",
      "Epoch 279/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 44us/step - loss: 1.5657 - acc: 0.4250 - val_loss: 1.7418 - val_acc: 0.4444\n",
      "\n",
      "Epoch 280/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 42us/step - loss: 1.6104 - acc: 0.4333 - val_loss: 1.7432 - val_acc: 0.4444\n",
      "\n",
      "Epoch 281/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.6182 - acc: 0.4500 - val_loss: 1.7419 - val_acc: 0.4306\n",
      "\n",
      "Epoch 282/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.5654 - acc: 0.4583 - val_loss: 1.7386 - val_acc: 0.4306\n",
      "\n",
      "Epoch 283/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.6367 - acc: 0.3833 - val_loss: 1.7382 - val_acc: 0.4306\n",
      "\n",
      "Epoch 284/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 57us/step - loss: 1.5835 - acc: 0.3833 - val_loss: 1.7396 - val_acc: 0.4444\n",
      "\n",
      "Epoch 285/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.5940 - acc: 0.4583 - val_loss: 1.7366 - val_acc: 0.4306\n",
      "\n",
      "Epoch 286/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.5921 - acc: 0.4250 - val_loss: 1.7362 - val_acc: 0.4306\n",
      "\n",
      "Epoch 287/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.5491 - acc: 0.4542 - val_loss: 1.7363 - val_acc: 0.4444\n",
      "\n",
      "Epoch 288/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.5880 - acc: 0.4458 - val_loss: 1.7371 - val_acc: 0.4444\n",
      "\n",
      "Epoch 289/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.5842 - acc: 0.3958 - val_loss: 1.7363 - val_acc: 0.4306\n",
      "\n",
      "Epoch 290/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.5237 - acc: 0.4500 - val_loss: 1.7385 - val_acc: 0.4444\n",
      "\n",
      "Epoch 291/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.5354 - acc: 0.4583 - val_loss: 1.7365 - val_acc: 0.4444\n",
      "\n",
      "Epoch 292/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.6338 - acc: 0.4000 - val_loss: 1.7370 - val_acc: 0.4444\n",
      "\n",
      "Epoch 293/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.5440 - acc: 0.4500 - val_loss: 1.7361 - val_acc: 0.4444\n",
      "\n",
      "Epoch 294/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.5625 - acc: 0.4167 - val_loss: 1.7349 - val_acc: 0.4444\n",
      "\n",
      "Epoch 295/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.5648 - acc: 0.4333 - val_loss: 1.7364 - val_acc: 0.4444\n",
      "\n",
      "Epoch 296/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.5829 - acc: 0.4542 - val_loss: 1.7364 - val_acc: 0.4444\n",
      "\n",
      "Epoch 297/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.6378 - acc: 0.4083 - val_loss: 1.7378 - val_acc: 0.4167\n",
      "\n",
      "Epoch 298/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.5463 - acc: 0.4625 - val_loss: 1.7384 - val_acc: 0.4167\n",
      "\n",
      "Epoch 299/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.5242 - acc: 0.4542 - val_loss: 1.7353 - val_acc: 0.4306\n",
      "\n",
      "Epoch 300/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.6015 - acc: 0.4292 - val_loss: 1.7375 - val_acc: 0.4167\n",
      "\n",
      "Epoch 301/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.5510 - acc: 0.4333 - val_loss: 1.7359 - val_acc: 0.4306\n",
      "\n",
      "Epoch 302/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.5727 - acc: 0.4250 - val_loss: 1.7342 - val_acc: 0.4306\n",
      "\n",
      "Epoch 303/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.5695 - acc: 0.4500 - val_loss: 1.7320 - val_acc: 0.4306\n",
      "\n",
      "Epoch 304/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.5783 - acc: 0.4417 - val_loss: 1.7309 - val_acc: 0.4306\n",
      "\n",
      "Epoch 305/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.5167 - acc: 0.4625 - val_loss: 1.7325 - val_acc: 0.4306\n",
      "\n",
      "Epoch 306/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.5125 - acc: 0.4375 - val_loss: 1.7302 - val_acc: 0.4444\n",
      "\n",
      "Epoch 307/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.5111 - acc: 0.4458 - val_loss: 1.7286 - val_acc: 0.4306\n",
      "\n",
      "Epoch 308/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.5749 - acc: 0.4417 - val_loss: 1.7298 - val_acc: 0.4167\n",
      "\n",
      "Epoch 309/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 1.5608 - acc: 0.4167 - val_loss: 1.7316 - val_acc: 0.4306\n",
      "\n",
      "Epoch 310/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.5233 - acc: 0.4375 - val_loss: 1.7312 - val_acc: 0.4306\n",
      "\n",
      "Epoch 311/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 48us/step - loss: 1.5788 - acc: 0.4292 - val_loss: 1.7312 - val_acc: 0.4306\n",
      "\n",
      "Epoch 312/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.5594 - acc: 0.4375 - val_loss: 1.7332 - val_acc: 0.4306\n",
      "\n",
      "Epoch 313/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 44us/step - loss: 1.4909 - acc: 0.4625 - val_loss: 1.7301 - val_acc: 0.4306\n",
      "\n",
      "Epoch 314/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.5586 - acc: 0.4333 - val_loss: 1.7309 - val_acc: 0.4306\n",
      "\n",
      "Epoch 315/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.5080 - acc: 0.4833 - val_loss: 1.7294 - val_acc: 0.4444\n",
      "\n",
      "Epoch 316/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.5325 - acc: 0.4500 - val_loss: 1.7283 - val_acc: 0.4306\n",
      "\n",
      "Epoch 317/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 39us/step - loss: 1.5956 - acc: 0.3917 - val_loss: 1.7297 - val_acc: 0.4444\n",
      "\n",
      "Epoch 318/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 65us/step - loss: 1.5462 - acc: 0.4458 - val_loss: 1.7272 - val_acc: 0.4167\n",
      "\n",
      "Epoch 319/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.5715 - acc: 0.4167 - val_loss: 1.7276 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 320/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.5588 - acc: 0.4333 - val_loss: 1.7316 - val_acc: 0.4306\n",
      "\n",
      "Epoch 321/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 1.5798 - acc: 0.4500 - val_loss: 1.7273 - val_acc: 0.4167\n",
      "\n",
      "Epoch 322/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.5993 - acc: 0.4333 - val_loss: 1.7258 - val_acc: 0.4306\n",
      "\n",
      "Epoch 323/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.5721 - acc: 0.4125 - val_loss: 1.7255 - val_acc: 0.4028\n",
      "\n",
      "Epoch 324/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.5321 - acc: 0.4750 - val_loss: 1.7280 - val_acc: 0.4167\n",
      "\n",
      "Epoch 325/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5139 - acc: 0.4750 - val_loss: 1.7270 - val_acc: 0.4167\n",
      "\n",
      "Epoch 326/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.5937 - acc: 0.4000 - val_loss: 1.7264 - val_acc: 0.4167\n",
      "\n",
      "Epoch 327/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.5203 - acc: 0.4500 - val_loss: 1.7258 - val_acc: 0.4306\n",
      "\n",
      "Epoch 328/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.5914 - acc: 0.4458 - val_loss: 1.7237 - val_acc: 0.4306\n",
      "\n",
      "Epoch 329/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.6372 - acc: 0.4125 - val_loss: 1.7250 - val_acc: 0.4306\n",
      "\n",
      "Epoch 330/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.5819 - acc: 0.4125 - val_loss: 1.7226 - val_acc: 0.4306\n",
      "\n",
      "Epoch 331/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.5501 - acc: 0.4667 - val_loss: 1.7228 - val_acc: 0.4306\n",
      "\n",
      "Epoch 332/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.5599 - acc: 0.4083 - val_loss: 1.7259 - val_acc: 0.4306\n",
      "\n",
      "Epoch 333/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.5770 - acc: 0.4167 - val_loss: 1.7274 - val_acc: 0.4167\n",
      "\n",
      "Epoch 334/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.5622 - acc: 0.4083 - val_loss: 1.7270 - val_acc: 0.4306\n",
      "\n",
      "Epoch 335/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.5352 - acc: 0.4208 - val_loss: 1.7265 - val_acc: 0.4306\n",
      "\n",
      "Epoch 336/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.5826 - acc: 0.4292 - val_loss: 1.7265 - val_acc: 0.4306\n",
      "\n",
      "Epoch 337/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.5326 - acc: 0.4458 - val_loss: 1.7258 - val_acc: 0.4306\n",
      "\n",
      "Epoch 338/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.5648 - acc: 0.4208 - val_loss: 1.7233 - val_acc: 0.4167\n",
      "\n",
      "Epoch 339/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5739 - acc: 0.4125 - val_loss: 1.7270 - val_acc: 0.4306\n",
      "\n",
      "Epoch 340/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5420 - acc: 0.4542 - val_loss: 1.7260 - val_acc: 0.4306\n",
      "\n",
      "Epoch 341/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.5457 - acc: 0.4208 - val_loss: 1.7250 - val_acc: 0.4444\n",
      "\n",
      "Epoch 342/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.5526 - acc: 0.4667 - val_loss: 1.7272 - val_acc: 0.4444\n",
      "\n",
      "Epoch 343/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4893 - acc: 0.4833 - val_loss: 1.7273 - val_acc: 0.4306\n",
      "\n",
      "Epoch 344/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5775 - acc: 0.4583 - val_loss: 1.7280 - val_acc: 0.4306\n",
      "\n",
      "Epoch 345/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 66us/step - loss: 1.5609 - acc: 0.4208 - val_loss: 1.7306 - val_acc: 0.4306\n",
      "\n",
      "Epoch 346/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.5762 - acc: 0.4583 - val_loss: 1.7311 - val_acc: 0.4444\n",
      "\n",
      "Epoch 347/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.5569 - acc: 0.4417 - val_loss: 1.7307 - val_acc: 0.4306\n",
      "\n",
      "Epoch 348/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.5613 - acc: 0.4125 - val_loss: 1.7294 - val_acc: 0.4028\n",
      "\n",
      "Epoch 349/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.5524 - acc: 0.4667 - val_loss: 1.7290 - val_acc: 0.4306\n",
      "\n",
      "Epoch 350/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 38us/step - loss: 1.5277 - acc: 0.4542 - val_loss: 1.7280 - val_acc: 0.4444\n",
      "\n",
      "Epoch 351/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.5562 - acc: 0.4667 - val_loss: 1.7304 - val_acc: 0.4167\n",
      "\n",
      "Epoch 352/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.5697 - acc: 0.4333 - val_loss: 1.7279 - val_acc: 0.4306\n",
      "\n",
      "Epoch 353/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.4896 - acc: 0.4292 - val_loss: 1.7265 - val_acc: 0.4028\n",
      "\n",
      "Epoch 354/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5402 - acc: 0.4292 - val_loss: 1.7243 - val_acc: 0.4167\n",
      "\n",
      "Epoch 355/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 127us/step - loss: 1.5415 - acc: 0.4542 - val_loss: 1.7230 - val_acc: 0.4306\n",
      "\n",
      "Epoch 356/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 106us/step - loss: 1.5388 - acc: 0.4500 - val_loss: 1.7222 - val_acc: 0.4444\n",
      "\n",
      "Epoch 357/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.4783 - acc: 0.4792 - val_loss: 1.7216 - val_acc: 0.4306\n",
      "\n",
      "Epoch 358/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.5390 - acc: 0.4375 - val_loss: 1.7217 - val_acc: 0.4306\n",
      "\n",
      "Epoch 359/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.5450 - acc: 0.4500 - val_loss: 1.7238 - val_acc: 0.4444\n",
      "\n",
      "Epoch 360/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.4847 - acc: 0.4958 - val_loss: 1.7189 - val_acc: 0.4306\n",
      "\n",
      "Epoch 361/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.5634 - acc: 0.4208 - val_loss: 1.7191 - val_acc: 0.4306\n",
      "\n",
      "Epoch 362/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.6121 - acc: 0.4083 - val_loss: 1.7201 - val_acc: 0.4306\n",
      "\n",
      "Epoch 363/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.5681 - acc: 0.4208 - val_loss: 1.7186 - val_acc: 0.4306\n",
      "\n",
      "Epoch 364/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5023 - acc: 0.4625 - val_loss: 1.7174 - val_acc: 0.4306\n",
      "\n",
      "Epoch 365/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5013 - acc: 0.4833 - val_loss: 1.7169 - val_acc: 0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 366/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.5318 - acc: 0.4375 - val_loss: 1.7159 - val_acc: 0.4028\n",
      "\n",
      "Epoch 367/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.5184 - acc: 0.4750 - val_loss: 1.7139 - val_acc: 0.4167\n",
      "\n",
      "Epoch 368/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5362 - acc: 0.4500 - val_loss: 1.7129 - val_acc: 0.4444\n",
      "\n",
      "Epoch 369/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.5606 - acc: 0.4125 - val_loss: 1.7147 - val_acc: 0.4444\n",
      "\n",
      "Epoch 370/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.4932 - acc: 0.4667 - val_loss: 1.7115 - val_acc: 0.4306\n",
      "\n",
      "Epoch 371/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 1.5049 - acc: 0.4833 - val_loss: 1.7121 - val_acc: 0.4167\n",
      "\n",
      "Epoch 372/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.5721 - acc: 0.4000 - val_loss: 1.7120 - val_acc: 0.4444\n",
      "\n",
      "Epoch 373/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.5177 - acc: 0.4375 - val_loss: 1.7119 - val_acc: 0.4444\n",
      "\n",
      "Epoch 374/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4912 - acc: 0.4292 - val_loss: 1.7144 - val_acc: 0.4306\n",
      "\n",
      "Epoch 375/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5245 - acc: 0.4167 - val_loss: 1.7134 - val_acc: 0.4167\n",
      "\n",
      "Epoch 376/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5368 - acc: 0.4292 - val_loss: 1.7139 - val_acc: 0.4167\n",
      "\n",
      "Epoch 377/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5269 - acc: 0.4500 - val_loss: 1.7152 - val_acc: 0.4306\n",
      "\n",
      "Epoch 378/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5255 - acc: 0.4333 - val_loss: 1.7136 - val_acc: 0.4444\n",
      "\n",
      "Epoch 379/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4693 - acc: 0.4625 - val_loss: 1.7144 - val_acc: 0.4306\n",
      "\n",
      "Epoch 380/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.5180 - acc: 0.4583 - val_loss: 1.7127 - val_acc: 0.4444\n",
      "\n",
      "Epoch 381/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 46us/step - loss: 1.5147 - acc: 0.4542 - val_loss: 1.7131 - val_acc: 0.4306\n",
      "\n",
      "Epoch 382/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.5230 - acc: 0.4542 - val_loss: 1.7163 - val_acc: 0.4306\n",
      "\n",
      "Epoch 383/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.5162 - acc: 0.4500 - val_loss: 1.7103 - val_acc: 0.4167\n",
      "\n",
      "Epoch 384/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.5124 - acc: 0.4750 - val_loss: 1.7111 - val_acc: 0.4444\n",
      "\n",
      "Epoch 385/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.4825 - acc: 0.4625 - val_loss: 1.7104 - val_acc: 0.4444\n",
      "\n",
      "Epoch 386/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.5286 - acc: 0.4333 - val_loss: 1.7138 - val_acc: 0.4444\n",
      "\n",
      "Epoch 387/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 56us/step - loss: 1.5450 - acc: 0.4083 - val_loss: 1.7125 - val_acc: 0.4306\n",
      "\n",
      "Epoch 388/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.5715 - acc: 0.4292 - val_loss: 1.7107 - val_acc: 0.4306\n",
      "\n",
      "Epoch 389/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.5003 - acc: 0.4333 - val_loss: 1.7077 - val_acc: 0.4444\n",
      "\n",
      "Epoch 390/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.5626 - acc: 0.4375 - val_loss: 1.7078 - val_acc: 0.4167\n",
      "\n",
      "Epoch 391/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 1.4927 - acc: 0.4625 - val_loss: 1.7095 - val_acc: 0.4167\n",
      "\n",
      "Epoch 392/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.5588 - acc: 0.4250 - val_loss: 1.7133 - val_acc: 0.4306\n",
      "\n",
      "Epoch 393/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.5489 - acc: 0.4458 - val_loss: 1.7107 - val_acc: 0.4167\n",
      "\n",
      "Epoch 394/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.5336 - acc: 0.4292 - val_loss: 1.7130 - val_acc: 0.4444\n",
      "\n",
      "Epoch 395/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.5730 - acc: 0.4250 - val_loss: 1.7133 - val_acc: 0.4306\n",
      "\n",
      "Epoch 396/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.5022 - acc: 0.4458 - val_loss: 1.7141 - val_acc: 0.4306\n",
      "\n",
      "Epoch 397/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.4529 - acc: 0.4583 - val_loss: 1.7140 - val_acc: 0.4444\n",
      "\n",
      "Epoch 398/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.4804 - acc: 0.4917 - val_loss: 1.7139 - val_acc: 0.4444\n",
      "\n",
      "Epoch 399/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.5201 - acc: 0.4667 - val_loss: 1.7130 - val_acc: 0.4306\n",
      "\n",
      "Epoch 400/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.5558 - acc: 0.4375 - val_loss: 1.7130 - val_acc: 0.4167\n",
      "\n",
      "Epoch 401/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.5202 - acc: 0.4500 - val_loss: 1.7120 - val_acc: 0.4306\n",
      "\n",
      "Epoch 402/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4719 - acc: 0.4917 - val_loss: 1.7096 - val_acc: 0.4444\n",
      "\n",
      "Epoch 403/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.4790 - acc: 0.4500 - val_loss: 1.7078 - val_acc: 0.4167\n",
      "\n",
      "Epoch 404/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.4988 - acc: 0.4542 - val_loss: 1.7069 - val_acc: 0.4444\n",
      "\n",
      "Epoch 405/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.4878 - acc: 0.4625 - val_loss: 1.7078 - val_acc: 0.4306\n",
      "\n",
      "Epoch 406/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4936 - acc: 0.4417 - val_loss: 1.7059 - val_acc: 0.4444\n",
      "\n",
      "Epoch 407/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5473 - acc: 0.4208 - val_loss: 1.7059 - val_acc: 0.4444\n",
      "\n",
      "Epoch 408/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.5076 - acc: 0.4000 - val_loss: 1.7053 - val_acc: 0.4306\n",
      "\n",
      "Epoch 409/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4647 - acc: 0.5000 - val_loss: 1.7023 - val_acc: 0.4167\n",
      "\n",
      "Epoch 410/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.4871 - acc: 0.4458 - val_loss: 1.7032 - val_acc: 0.4028\n",
      "\n",
      "Epoch 411/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.4934 - acc: 0.4625 - val_loss: 1.7029 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 412/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 69us/step - loss: 1.5281 - acc: 0.4792 - val_loss: 1.7039 - val_acc: 0.4167\n",
      "\n",
      "Epoch 413/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.6141 - acc: 0.4042 - val_loss: 1.7026 - val_acc: 0.4167\n",
      "\n",
      "Epoch 414/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.4943 - acc: 0.4500 - val_loss: 1.7048 - val_acc: 0.4306\n",
      "\n",
      "Epoch 415/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.4717 - acc: 0.4875 - val_loss: 1.7033 - val_acc: 0.4444\n",
      "\n",
      "Epoch 416/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.5022 - acc: 0.4417 - val_loss: 1.7042 - val_acc: 0.4444\n",
      "\n",
      "Epoch 417/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.5257 - acc: 0.4583 - val_loss: 1.7025 - val_acc: 0.4444\n",
      "\n",
      "Epoch 418/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 28us/step - loss: 1.4969 - acc: 0.4750 - val_loss: 1.7040 - val_acc: 0.4306\n",
      "\n",
      "Epoch 419/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 29us/step - loss: 1.4799 - acc: 0.4625 - val_loss: 1.7043 - val_acc: 0.4167\n",
      "\n",
      "Epoch 420/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 40us/step - loss: 1.4704 - acc: 0.4750 - val_loss: 1.7053 - val_acc: 0.4306\n",
      "\n",
      "Epoch 421/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.5256 - acc: 0.4375 - val_loss: 1.7049 - val_acc: 0.4444\n",
      "\n",
      "Epoch 422/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.5005 - acc: 0.4667 - val_loss: 1.7011 - val_acc: 0.4167\n",
      "\n",
      "Epoch 423/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.4977 - acc: 0.4333 - val_loss: 1.7062 - val_acc: 0.4306\n",
      "\n",
      "Epoch 424/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 1.4669 - acc: 0.4667 - val_loss: 1.7052 - val_acc: 0.4444\n",
      "\n",
      "Epoch 425/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.5328 - acc: 0.4333 - val_loss: 1.7036 - val_acc: 0.4306\n",
      "\n",
      "Epoch 426/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.4265 - acc: 0.4833 - val_loss: 1.7013 - val_acc: 0.4028\n",
      "\n",
      "Epoch 427/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.4733 - acc: 0.5208 - val_loss: 1.7077 - val_acc: 0.4306\n",
      "\n",
      "Epoch 428/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.4881 - acc: 0.4792 - val_loss: 1.7057 - val_acc: 0.4306\n",
      "\n",
      "Epoch 429/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.4774 - acc: 0.4667 - val_loss: 1.7048 - val_acc: 0.4306\n",
      "\n",
      "Epoch 430/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4521 - acc: 0.4542 - val_loss: 1.7021 - val_acc: 0.4306\n",
      "\n",
      "Epoch 431/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.5262 - acc: 0.4500 - val_loss: 1.7032 - val_acc: 0.4306\n",
      "\n",
      "Epoch 432/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4669 - acc: 0.4542 - val_loss: 1.7061 - val_acc: 0.4306\n",
      "\n",
      "Epoch 433/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 125us/step - loss: 1.5720 - acc: 0.4333 - val_loss: 1.7051 - val_acc: 0.4167\n",
      "\n",
      "Epoch 434/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.4679 - acc: 0.4750 - val_loss: 1.7013 - val_acc: 0.4028\n",
      "\n",
      "Epoch 435/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.4482 - acc: 0.5083 - val_loss: 1.6995 - val_acc: 0.4167\n",
      "\n",
      "Epoch 436/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.4833 - acc: 0.4583 - val_loss: 1.6991 - val_acc: 0.4167\n",
      "\n",
      "Epoch 437/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.5035 - acc: 0.4542 - val_loss: 1.6998 - val_acc: 0.4167\n",
      "\n",
      "Epoch 438/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.5089 - acc: 0.4625 - val_loss: 1.6989 - val_acc: 0.4306\n",
      "\n",
      "Epoch 439/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.4594 - acc: 0.4750 - val_loss: 1.7037 - val_acc: 0.4306\n",
      "\n",
      "Epoch 440/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.4485 - acc: 0.4958 - val_loss: 1.7056 - val_acc: 0.4444\n",
      "\n",
      "Epoch 441/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.5340 - acc: 0.3875 - val_loss: 1.7070 - val_acc: 0.4583\n",
      "\n",
      "Epoch 442/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4909 - acc: 0.5125 - val_loss: 1.7030 - val_acc: 0.4167\n",
      "\n",
      "Epoch 443/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4581 - acc: 0.5000 - val_loss: 1.6993 - val_acc: 0.4306\n",
      "\n",
      "Epoch 444/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.5167 - acc: 0.4542 - val_loss: 1.6959 - val_acc: 0.4444\n",
      "\n",
      "Epoch 445/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 66us/step - loss: 1.4644 - acc: 0.5083 - val_loss: 1.6957 - val_acc: 0.4167\n",
      "\n",
      "Epoch 446/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4222 - acc: 0.5208 - val_loss: 1.6994 - val_acc: 0.4444\n",
      "\n",
      "Epoch 447/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.4553 - acc: 0.4750 - val_loss: 1.7013 - val_acc: 0.4306\n",
      "\n",
      "Epoch 448/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.5111 - acc: 0.4542 - val_loss: 1.7029 - val_acc: 0.4306\n",
      "\n",
      "Epoch 449/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.5053 - acc: 0.4125 - val_loss: 1.7021 - val_acc: 0.4167\n",
      "\n",
      "Epoch 450/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4798 - acc: 0.5208 - val_loss: 1.7008 - val_acc: 0.4306\n",
      "\n",
      "Epoch 451/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 62us/step - loss: 1.4285 - acc: 0.4708 - val_loss: 1.6994 - val_acc: 0.4306\n",
      "\n",
      "Epoch 452/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.4244 - acc: 0.4792 - val_loss: 1.7003 - val_acc: 0.4306\n",
      "\n",
      "Epoch 453/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.4799 - acc: 0.4542 - val_loss: 1.7029 - val_acc: 0.4583\n",
      "\n",
      "Epoch 454/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.4554 - acc: 0.4875 - val_loss: 1.7040 - val_acc: 0.4583\n",
      "\n",
      "Epoch 455/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.4869 - acc: 0.4500 - val_loss: 1.6995 - val_acc: 0.4444\n",
      "\n",
      "Epoch 456/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.5419 - acc: 0.4083 - val_loss: 1.7008 - val_acc: 0.4444\n",
      "\n",
      "Epoch 457/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.5217 - acc: 0.4500 - val_loss: 1.6960 - val_acc: 0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 458/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 1.4583 - acc: 0.4792 - val_loss: 1.6974 - val_acc: 0.4444\n",
      "\n",
      "Epoch 459/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.4203 - acc: 0.5208 - val_loss: 1.6961 - val_acc: 0.4444\n",
      "\n",
      "Epoch 460/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.4505 - acc: 0.4375 - val_loss: 1.6949 - val_acc: 0.4583\n",
      "\n",
      "Epoch 461/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.4319 - acc: 0.5042 - val_loss: 1.6962 - val_acc: 0.4306\n",
      "\n",
      "Epoch 462/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.4498 - acc: 0.4625 - val_loss: 1.6971 - val_acc: 0.4444\n",
      "\n",
      "Epoch 463/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 1.4911 - acc: 0.4292 - val_loss: 1.6965 - val_acc: 0.4583\n",
      "\n",
      "Epoch 464/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.5080 - acc: 0.4292 - val_loss: 1.6958 - val_acc: 0.4583\n",
      "\n",
      "Epoch 465/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.4734 - acc: 0.4750 - val_loss: 1.6962 - val_acc: 0.4444\n",
      "\n",
      "Epoch 466/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4669 - acc: 0.5042 - val_loss: 1.6970 - val_acc: 0.4028\n",
      "\n",
      "Epoch 467/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.4361 - acc: 0.4875 - val_loss: 1.6933 - val_acc: 0.4306\n",
      "\n",
      "Epoch 468/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4082 - acc: 0.5125 - val_loss: 1.6940 - val_acc: 0.4306\n",
      "\n",
      "Epoch 469/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.4533 - acc: 0.4917 - val_loss: 1.6963 - val_acc: 0.4306\n",
      "\n",
      "Epoch 470/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 67us/step - loss: 1.4543 - acc: 0.4500 - val_loss: 1.6970 - val_acc: 0.4306\n",
      "\n",
      "Epoch 471/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.5003 - acc: 0.4583 - val_loss: 1.6991 - val_acc: 0.4306\n",
      "\n",
      "Epoch 472/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.4553 - acc: 0.4917 - val_loss: 1.6992 - val_acc: 0.4306\n",
      "\n",
      "Epoch 473/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.5138 - acc: 0.4417 - val_loss: 1.6980 - val_acc: 0.4028\n",
      "\n",
      "Epoch 474/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.4261 - acc: 0.4750 - val_loss: 1.6968 - val_acc: 0.4167\n",
      "\n",
      "Epoch 475/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.4929 - acc: 0.4208 - val_loss: 1.6993 - val_acc: 0.4306\n",
      "\n",
      "Epoch 476/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4520 - acc: 0.4750 - val_loss: 1.7014 - val_acc: 0.4167\n",
      "\n",
      "Epoch 477/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.4385 - acc: 0.4708 - val_loss: 1.7005 - val_acc: 0.4167\n",
      "\n",
      "Epoch 478/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.5139 - acc: 0.4250 - val_loss: 1.6982 - val_acc: 0.4167\n",
      "\n",
      "Epoch 479/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4183 - acc: 0.4792 - val_loss: 1.6958 - val_acc: 0.4306\n",
      "\n",
      "Epoch 480/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.4696 - acc: 0.4667 - val_loss: 1.6963 - val_acc: 0.4167\n",
      "\n",
      "Epoch 481/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4761 - acc: 0.4375 - val_loss: 1.6981 - val_acc: 0.4444\n",
      "\n",
      "Epoch 482/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.4679 - acc: 0.4542 - val_loss: 1.6978 - val_acc: 0.4167\n",
      "\n",
      "Epoch 483/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.4906 - acc: 0.4583 - val_loss: 1.7014 - val_acc: 0.4306\n",
      "\n",
      "Epoch 484/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.4773 - acc: 0.4500 - val_loss: 1.7025 - val_acc: 0.4167\n",
      "\n",
      "Epoch 485/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 59us/step - loss: 1.5051 - acc: 0.4583 - val_loss: 1.7003 - val_acc: 0.4167\n",
      "\n",
      "Epoch 486/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 112us/step - loss: 1.4636 - acc: 0.4833 - val_loss: 1.6990 - val_acc: 0.4028\n",
      "\n",
      "Epoch 487/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.5260 - acc: 0.4458 - val_loss: 1.6969 - val_acc: 0.4306\n",
      "\n",
      "Epoch 488/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.4281 - acc: 0.4500 - val_loss: 1.6984 - val_acc: 0.4028\n",
      "\n",
      "Epoch 489/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.4754 - acc: 0.5167 - val_loss: 1.6936 - val_acc: 0.4444\n",
      "\n",
      "Epoch 490/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.4420 - acc: 0.4792 - val_loss: 1.6911 - val_acc: 0.4306\n",
      "\n",
      "Epoch 491/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.4122 - acc: 0.4708 - val_loss: 1.6930 - val_acc: 0.4306\n",
      "\n",
      "Epoch 492/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.4885 - acc: 0.4708 - val_loss: 1.6955 - val_acc: 0.4583\n",
      "\n",
      "Epoch 493/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 130us/step - loss: 1.4455 - acc: 0.4458 - val_loss: 1.6997 - val_acc: 0.4444\n",
      "\n",
      "Epoch 494/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.4645 - acc: 0.4625 - val_loss: 1.7016 - val_acc: 0.4444\n",
      "\n",
      "Epoch 495/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.4928 - acc: 0.4333 - val_loss: 1.7018 - val_acc: 0.4167\n",
      "\n",
      "Epoch 496/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.4085 - acc: 0.4917 - val_loss: 1.7012 - val_acc: 0.4444\n",
      "\n",
      "Epoch 497/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4486 - acc: 0.4375 - val_loss: 1.7005 - val_acc: 0.4167\n",
      "\n",
      "Epoch 498/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4980 - acc: 0.4583 - val_loss: 1.6995 - val_acc: 0.4167\n",
      "\n",
      "Epoch 499/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.4633 - acc: 0.4583 - val_loss: 1.6985 - val_acc: 0.4444\n",
      "\n",
      "Epoch 500/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.4511 - acc: 0.4583 - val_loss: 1.6983 - val_acc: 0.4167\n",
      "\n",
      "Epoch 501/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.4002 - acc: 0.4833 - val_loss: 1.6997 - val_acc: 0.4306\n",
      "\n",
      "Epoch 502/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4528 - acc: 0.4708 - val_loss: 1.6959 - val_acc: 0.4028\n",
      "\n",
      "Epoch 503/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3932 - acc: 0.4375 - val_loss: 1.6963 - val_acc: 0.4028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 504/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.4475 - acc: 0.4542 - val_loss: 1.6932 - val_acc: 0.4306\n",
      "\n",
      "Epoch 505/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.4780 - acc: 0.4500 - val_loss: 1.6922 - val_acc: 0.4028\n",
      "\n",
      "Epoch 506/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.4704 - acc: 0.4542 - val_loss: 1.6937 - val_acc: 0.4444\n",
      "\n",
      "Epoch 507/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.5039 - acc: 0.4708 - val_loss: 1.6957 - val_acc: 0.4583\n",
      "\n",
      "Epoch 508/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4510 - acc: 0.4625 - val_loss: 1.6943 - val_acc: 0.4583\n",
      "\n",
      "Epoch 509/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.4604 - acc: 0.4583 - val_loss: 1.6990 - val_acc: 0.4583\n",
      "\n",
      "Epoch 510/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4628 - acc: 0.4625 - val_loss: 1.7023 - val_acc: 0.4028\n",
      "\n",
      "Epoch 511/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.4659 - acc: 0.4333 - val_loss: 1.6991 - val_acc: 0.4306\n",
      "\n",
      "Epoch 512/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.4713 - acc: 0.4792 - val_loss: 1.7003 - val_acc: 0.4167\n",
      "\n",
      "Epoch 513/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.4564 - acc: 0.4917 - val_loss: 1.6953 - val_acc: 0.4028\n",
      "\n",
      "Epoch 514/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.4584 - acc: 0.4583 - val_loss: 1.6969 - val_acc: 0.4028\n",
      "\n",
      "Epoch 515/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.4872 - acc: 0.4083 - val_loss: 1.6948 - val_acc: 0.4028\n",
      "\n",
      "Epoch 516/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.4097 - acc: 0.5083 - val_loss: 1.6954 - val_acc: 0.4167\n",
      "\n",
      "Epoch 517/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4200 - acc: 0.4917 - val_loss: 1.6952 - val_acc: 0.4306\n",
      "\n",
      "Epoch 518/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.4124 - acc: 0.4500 - val_loss: 1.6978 - val_acc: 0.4028\n",
      "\n",
      "Epoch 519/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 52us/step - loss: 1.4654 - acc: 0.4750 - val_loss: 1.6981 - val_acc: 0.4028\n",
      "\n",
      "Epoch 520/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.4560 - acc: 0.4917 - val_loss: 1.6988 - val_acc: 0.4028\n",
      "\n",
      "Epoch 521/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 1.4597 - acc: 0.4958 - val_loss: 1.7013 - val_acc: 0.4028\n",
      "\n",
      "Epoch 522/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.4033 - acc: 0.5125 - val_loss: 1.7005 - val_acc: 0.4167\n",
      "\n",
      "Epoch 523/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.4294 - acc: 0.5000 - val_loss: 1.6978 - val_acc: 0.4167\n",
      "\n",
      "Epoch 524/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 106us/step - loss: 1.4412 - acc: 0.4667 - val_loss: 1.6974 - val_acc: 0.4028\n",
      "\n",
      "Epoch 525/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.4328 - acc: 0.4708 - val_loss: 1.6980 - val_acc: 0.4306\n",
      "\n",
      "Epoch 526/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.5187 - acc: 0.4000 - val_loss: 1.6987 - val_acc: 0.4167\n",
      "\n",
      "Epoch 527/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.4664 - acc: 0.4958 - val_loss: 1.7020 - val_acc: 0.4306\n",
      "\n",
      "Epoch 528/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.4180 - acc: 0.5083 - val_loss: 1.7018 - val_acc: 0.4583\n",
      "\n",
      "Epoch 529/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.5176 - acc: 0.4500 - val_loss: 1.7017 - val_acc: 0.4306\n",
      "\n",
      "Epoch 530/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.4391 - acc: 0.4417 - val_loss: 1.7008 - val_acc: 0.4583\n",
      "\n",
      "Epoch 531/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4143 - acc: 0.5208 - val_loss: 1.7017 - val_acc: 0.4444\n",
      "\n",
      "Epoch 532/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4744 - acc: 0.4667 - val_loss: 1.7016 - val_acc: 0.4444\n",
      "\n",
      "Epoch 533/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.4306 - acc: 0.4833 - val_loss: 1.6995 - val_acc: 0.4306\n",
      "\n",
      "Epoch 534/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.4257 - acc: 0.4667 - val_loss: 1.6997 - val_acc: 0.4306\n",
      "\n",
      "Epoch 535/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4186 - acc: 0.4708 - val_loss: 1.6998 - val_acc: 0.4306\n",
      "\n",
      "Epoch 536/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.4938 - acc: 0.4417 - val_loss: 1.7022 - val_acc: 0.4306\n",
      "\n",
      "Epoch 537/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4464 - acc: 0.5000 - val_loss: 1.6966 - val_acc: 0.4444\n",
      "\n",
      "Epoch 538/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.4533 - acc: 0.4750 - val_loss: 1.7010 - val_acc: 0.4444\n",
      "\n",
      "Epoch 539/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4152 - acc: 0.4792 - val_loss: 1.6967 - val_acc: 0.4444\n",
      "\n",
      "Epoch 540/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.4170 - acc: 0.5042 - val_loss: 1.6990 - val_acc: 0.4306\n",
      "\n",
      "Epoch 541/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.4064 - acc: 0.5042 - val_loss: 1.6977 - val_acc: 0.4444\n",
      "\n",
      "Epoch 542/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4614 - acc: 0.4708 - val_loss: 1.6986 - val_acc: 0.4306\n",
      "\n",
      "Epoch 543/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4711 - acc: 0.4583 - val_loss: 1.7002 - val_acc: 0.4583\n",
      "\n",
      "Epoch 544/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.4352 - acc: 0.4583 - val_loss: 1.6996 - val_acc: 0.4583\n",
      "\n",
      "Epoch 545/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.4143 - acc: 0.5167 - val_loss: 1.7008 - val_acc: 0.4167\n",
      "\n",
      "Epoch 546/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 63us/step - loss: 1.4496 - acc: 0.4583 - val_loss: 1.7005 - val_acc: 0.4167\n",
      "\n",
      "Epoch 547/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.4320 - acc: 0.4792 - val_loss: 1.6988 - val_acc: 0.4306\n",
      "\n",
      "Epoch 548/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.4303 - acc: 0.4375 - val_loss: 1.7007 - val_acc: 0.4306\n",
      "\n",
      "Epoch 549/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.4382 - acc: 0.5042 - val_loss: 1.6997 - val_acc: 0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 550/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.4485 - acc: 0.4333 - val_loss: 1.6991 - val_acc: 0.4306\n",
      "\n",
      "Epoch 551/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.4368 - acc: 0.4500 - val_loss: 1.6951 - val_acc: 0.4306\n",
      "\n",
      "Epoch 552/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 106us/step - loss: 1.4227 - acc: 0.4875 - val_loss: 1.6970 - val_acc: 0.4167\n",
      "\n",
      "Epoch 553/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.4600 - acc: 0.4542 - val_loss: 1.6982 - val_acc: 0.4306\n",
      "\n",
      "Epoch 554/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.4945 - acc: 0.4833 - val_loss: 1.6992 - val_acc: 0.4306\n",
      "\n",
      "Epoch 555/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.4116 - acc: 0.5000 - val_loss: 1.6962 - val_acc: 0.4306\n",
      "\n",
      "Epoch 556/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.4467 - acc: 0.4708 - val_loss: 1.6954 - val_acc: 0.4028\n",
      "\n",
      "Epoch 557/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.4273 - acc: 0.5042 - val_loss: 1.6988 - val_acc: 0.4167\n",
      "\n",
      "Epoch 558/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.4231 - acc: 0.4458 - val_loss: 1.7010 - val_acc: 0.4028\n",
      "\n",
      "Epoch 559/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4595 - acc: 0.4292 - val_loss: 1.7000 - val_acc: 0.4167\n",
      "\n",
      "Epoch 560/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.4230 - acc: 0.4583 - val_loss: 1.7036 - val_acc: 0.4583\n",
      "\n",
      "Epoch 561/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4445 - acc: 0.4958 - val_loss: 1.6976 - val_acc: 0.4167\n",
      "\n",
      "Epoch 562/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.4439 - acc: 0.4833 - val_loss: 1.6955 - val_acc: 0.4306\n",
      "\n",
      "Epoch 563/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.4289 - acc: 0.5125 - val_loss: 1.6979 - val_acc: 0.4444\n",
      "\n",
      "Epoch 564/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.3966 - acc: 0.5125 - val_loss: 1.6960 - val_acc: 0.4306\n",
      "\n",
      "Epoch 565/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.4916 - acc: 0.4417 - val_loss: 1.7013 - val_acc: 0.4306\n",
      "\n",
      "Epoch 566/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 147us/step - loss: 1.4000 - acc: 0.4750 - val_loss: 1.6999 - val_acc: 0.4167\n",
      "\n",
      "Epoch 567/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.4205 - acc: 0.4958 - val_loss: 1.7021 - val_acc: 0.4167\n",
      "\n",
      "Epoch 568/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.4782 - acc: 0.4417 - val_loss: 1.7046 - val_acc: 0.4167\n",
      "\n",
      "Epoch 569/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.3717 - acc: 0.5000 - val_loss: 1.7015 - val_acc: 0.4306\n",
      "\n",
      "Epoch 570/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.4172 - acc: 0.5083 - val_loss: 1.6954 - val_acc: 0.4306\n",
      "\n",
      "Epoch 571/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.4539 - acc: 0.4542 - val_loss: 1.6961 - val_acc: 0.4306\n",
      "\n",
      "Epoch 572/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4411 - acc: 0.4667 - val_loss: 1.6963 - val_acc: 0.4167\n",
      "\n",
      "Epoch 573/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4536 - acc: 0.4542 - val_loss: 1.6962 - val_acc: 0.4167\n",
      "\n",
      "Epoch 574/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.4222 - acc: 0.4750 - val_loss: 1.6983 - val_acc: 0.4444\n",
      "\n",
      "Epoch 575/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.3938 - acc: 0.5125 - val_loss: 1.6964 - val_acc: 0.4722\n",
      "\n",
      "Epoch 576/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4618 - acc: 0.4500 - val_loss: 1.6977 - val_acc: 0.4583\n",
      "\n",
      "Epoch 577/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3675 - acc: 0.5250 - val_loss: 1.6996 - val_acc: 0.4444\n",
      "\n",
      "Epoch 578/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4748 - acc: 0.4625 - val_loss: 1.6951 - val_acc: 0.4583\n",
      "\n",
      "Epoch 579/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 56us/step - loss: 1.4019 - acc: 0.4542 - val_loss: 1.6962 - val_acc: 0.4167\n",
      "\n",
      "Epoch 580/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.3991 - acc: 0.4833 - val_loss: 1.6945 - val_acc: 0.4444\n",
      "\n",
      "Epoch 581/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.3624 - acc: 0.4875 - val_loss: 1.6976 - val_acc: 0.4167\n",
      "\n",
      "Epoch 582/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 45us/step - loss: 1.3705 - acc: 0.5000 - val_loss: 1.6936 - val_acc: 0.4167\n",
      "\n",
      "Epoch 583/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.3968 - acc: 0.5167 - val_loss: 1.7004 - val_acc: 0.4167\n",
      "\n",
      "Epoch 584/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.3121 - acc: 0.5292 - val_loss: 1.6933 - val_acc: 0.4306\n",
      "\n",
      "Epoch 585/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.4281 - acc: 0.4542 - val_loss: 1.6969 - val_acc: 0.4167\n",
      "\n",
      "Epoch 586/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 40us/step - loss: 1.4366 - acc: 0.4708 - val_loss: 1.6910 - val_acc: 0.4444\n",
      "\n",
      "Epoch 587/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.4532 - acc: 0.4667 - val_loss: 1.6952 - val_acc: 0.4028\n",
      "\n",
      "Epoch 588/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.4528 - acc: 0.4958 - val_loss: 1.6951 - val_acc: 0.3889\n",
      "\n",
      "Epoch 589/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.3859 - acc: 0.4875 - val_loss: 1.6939 - val_acc: 0.4028\n",
      "\n",
      "Epoch 590/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 1.4207 - acc: 0.5208 - val_loss: 1.6921 - val_acc: 0.4028\n",
      "\n",
      "Epoch 591/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.3986 - acc: 0.4750 - val_loss: 1.6936 - val_acc: 0.3750\n",
      "\n",
      "Epoch 592/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.4529 - acc: 0.4583 - val_loss: 1.6942 - val_acc: 0.4167\n",
      "\n",
      "Epoch 593/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.4357 - acc: 0.4458 - val_loss: 1.6988 - val_acc: 0.4167\n",
      "\n",
      "Epoch 594/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3858 - acc: 0.4958 - val_loss: 1.6993 - val_acc: 0.3889\n",
      "\n",
      "Epoch 595/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.3535 - acc: 0.5333 - val_loss: 1.7008 - val_acc: 0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 596/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 1.3435 - acc: 0.5125 - val_loss: 1.6949 - val_acc: 0.4028\n",
      "\n",
      "Epoch 597/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.4390 - acc: 0.4750 - val_loss: 1.6939 - val_acc: 0.4028\n",
      "\n",
      "Epoch 598/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 1.4027 - acc: 0.5125 - val_loss: 1.6962 - val_acc: 0.3889\n",
      "\n",
      "Epoch 599/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.3900 - acc: 0.4875 - val_loss: 1.6959 - val_acc: 0.4028\n",
      "\n",
      "Epoch 600/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.4071 - acc: 0.4917 - val_loss: 1.6932 - val_acc: 0.4028\n",
      "\n",
      "Epoch 601/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.3839 - acc: 0.5042 - val_loss: 1.6992 - val_acc: 0.4028\n",
      "\n",
      "Epoch 602/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4439 - acc: 0.4583 - val_loss: 1.7005 - val_acc: 0.4167\n",
      "\n",
      "Epoch 603/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.4879 - acc: 0.4458 - val_loss: 1.7055 - val_acc: 0.4306\n",
      "\n",
      "Epoch 604/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.4000 - acc: 0.4792 - val_loss: 1.7050 - val_acc: 0.4444\n",
      "\n",
      "Epoch 605/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.3900 - acc: 0.4792 - val_loss: 1.7021 - val_acc: 0.4028\n",
      "\n",
      "Epoch 606/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3904 - acc: 0.4792 - val_loss: 1.7000 - val_acc: 0.4167\n",
      "\n",
      "Epoch 607/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.4702 - acc: 0.4583 - val_loss: 1.7034 - val_acc: 0.3889\n",
      "\n",
      "Epoch 608/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.4352 - acc: 0.4542 - val_loss: 1.6982 - val_acc: 0.4167\n",
      "\n",
      "Epoch 609/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.3748 - acc: 0.5125 - val_loss: 1.6997 - val_acc: 0.4028\n",
      "\n",
      "Epoch 610/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.3363 - acc: 0.5083 - val_loss: 1.7056 - val_acc: 0.3889\n",
      "\n",
      "Epoch 611/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.4248 - acc: 0.4667 - val_loss: 1.6943 - val_acc: 0.4444\n",
      "\n",
      "Epoch 612/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.3847 - acc: 0.5125 - val_loss: 1.6932 - val_acc: 0.4167\n",
      "\n",
      "Epoch 613/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 69us/step - loss: 1.4087 - acc: 0.5167 - val_loss: 1.6964 - val_acc: 0.4167\n",
      "\n",
      "Epoch 614/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 43us/step - loss: 1.4123 - acc: 0.4917 - val_loss: 1.6939 - val_acc: 0.3889\n",
      "\n",
      "Epoch 615/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4220 - acc: 0.4458 - val_loss: 1.6931 - val_acc: 0.4444\n",
      "\n",
      "Epoch 616/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4249 - acc: 0.4708 - val_loss: 1.6984 - val_acc: 0.4028\n",
      "\n",
      "Epoch 617/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.2739 - acc: 0.5292 - val_loss: 1.6978 - val_acc: 0.3889\n",
      "\n",
      "Epoch 618/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 29us/step - loss: 1.3426 - acc: 0.5042 - val_loss: 1.6957 - val_acc: 0.3750\n",
      "\n",
      "Epoch 619/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.4582 - acc: 0.4500 - val_loss: 1.6937 - val_acc: 0.4306\n",
      "\n",
      "Epoch 620/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.3405 - acc: 0.5167 - val_loss: 1.6939 - val_acc: 0.4028\n",
      "\n",
      "Epoch 621/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 51us/step - loss: 1.3596 - acc: 0.5167 - val_loss: 1.6923 - val_acc: 0.3889\n",
      "\n",
      "Epoch 622/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.3602 - acc: 0.5000 - val_loss: 1.7007 - val_acc: 0.4028\n",
      "\n",
      "Epoch 623/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.4243 - acc: 0.4500 - val_loss: 1.6969 - val_acc: 0.3889\n",
      "\n",
      "Epoch 624/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.4213 - acc: 0.4708 - val_loss: 1.6960 - val_acc: 0.3750\n",
      "\n",
      "Epoch 625/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.4670 - acc: 0.4625 - val_loss: 1.6961 - val_acc: 0.3750\n",
      "\n",
      "Epoch 626/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.4053 - acc: 0.4750 - val_loss: 1.6977 - val_acc: 0.4028\n",
      "\n",
      "Epoch 627/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.4094 - acc: 0.4542 - val_loss: 1.7006 - val_acc: 0.3889\n",
      "\n",
      "Epoch 628/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.4281 - acc: 0.4667 - val_loss: 1.6954 - val_acc: 0.4444\n",
      "\n",
      "Epoch 629/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 131us/step - loss: 1.4977 - acc: 0.4458 - val_loss: 1.6962 - val_acc: 0.4167\n",
      "\n",
      "Epoch 630/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.4284 - acc: 0.4542 - val_loss: 1.6944 - val_acc: 0.4167\n",
      "\n",
      "Epoch 631/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.3294 - acc: 0.4958 - val_loss: 1.6901 - val_acc: 0.3750\n",
      "\n",
      "Epoch 632/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.3757 - acc: 0.4958 - val_loss: 1.6966 - val_acc: 0.3889\n",
      "\n",
      "Epoch 633/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.4261 - acc: 0.4542 - val_loss: 1.6960 - val_acc: 0.4028\n",
      "\n",
      "Epoch 634/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.3423 - acc: 0.5208 - val_loss: 1.6934 - val_acc: 0.4028\n",
      "\n",
      "Epoch 635/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.3686 - acc: 0.4542 - val_loss: 1.6954 - val_acc: 0.3889\n",
      "\n",
      "Epoch 636/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.3882 - acc: 0.4792 - val_loss: 1.6964 - val_acc: 0.3750\n",
      "\n",
      "Epoch 637/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.4254 - acc: 0.5125 - val_loss: 1.6943 - val_acc: 0.4167\n",
      "\n",
      "Epoch 638/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.3760 - acc: 0.4875 - val_loss: 1.6913 - val_acc: 0.4583\n",
      "\n",
      "Epoch 639/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.4133 - acc: 0.5000 - val_loss: 1.6980 - val_acc: 0.4722\n",
      "\n",
      "Epoch 640/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.4018 - acc: 0.4708 - val_loss: 1.7014 - val_acc: 0.4167\n",
      "\n",
      "Epoch 641/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.3322 - acc: 0.5125 - val_loss: 1.7042 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 642/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3295 - acc: 0.5417 - val_loss: 1.6968 - val_acc: 0.4444\n",
      "\n",
      "Epoch 643/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.3803 - acc: 0.4833 - val_loss: 1.7002 - val_acc: 0.3750\n",
      "\n",
      "Epoch 644/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 70us/step - loss: 1.3730 - acc: 0.4750 - val_loss: 1.7082 - val_acc: 0.3889\n",
      "\n",
      "Epoch 645/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.3684 - acc: 0.4958 - val_loss: 1.6958 - val_acc: 0.4306\n",
      "\n",
      "Epoch 646/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3717 - acc: 0.4583 - val_loss: 1.6996 - val_acc: 0.4028\n",
      "\n",
      "Epoch 647/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4174 - acc: 0.4542 - val_loss: 1.7036 - val_acc: 0.3889\n",
      "\n",
      "Epoch 648/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.3921 - acc: 0.4875 - val_loss: 1.6993 - val_acc: 0.4028\n",
      "\n",
      "Epoch 649/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.3867 - acc: 0.4292 - val_loss: 1.7050 - val_acc: 0.3889\n",
      "\n",
      "Epoch 650/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.3861 - acc: 0.5167 - val_loss: 1.7093 - val_acc: 0.3889\n",
      "\n",
      "Epoch 651/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2984 - acc: 0.5625 - val_loss: 1.7097 - val_acc: 0.4028\n",
      "\n",
      "Epoch 652/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4406 - acc: 0.4875 - val_loss: 1.7014 - val_acc: 0.4167\n",
      "\n",
      "Epoch 653/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.3711 - acc: 0.4750 - val_loss: 1.7016 - val_acc: 0.4444\n",
      "\n",
      "Epoch 654/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 42us/step - loss: 1.4361 - acc: 0.4167 - val_loss: 1.6997 - val_acc: 0.4306\n",
      "\n",
      "Epoch 655/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 125us/step - loss: 1.4574 - acc: 0.4458 - val_loss: 1.7055 - val_acc: 0.3889\n",
      "\n",
      "Epoch 656/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.4058 - acc: 0.5042 - val_loss: 1.7006 - val_acc: 0.4028\n",
      "\n",
      "Epoch 657/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.3810 - acc: 0.4833 - val_loss: 1.6968 - val_acc: 0.4028\n",
      "\n",
      "Epoch 658/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 126us/step - loss: 1.3787 - acc: 0.4708 - val_loss: 1.6938 - val_acc: 0.4167\n",
      "\n",
      "Epoch 659/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3099 - acc: 0.5375 - val_loss: 1.6950 - val_acc: 0.3889\n",
      "\n",
      "Epoch 660/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3198 - acc: 0.4792 - val_loss: 1.6942 - val_acc: 0.4028\n",
      "\n",
      "Epoch 661/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3990 - acc: 0.5000 - val_loss: 1.6991 - val_acc: 0.3889\n",
      "\n",
      "Epoch 662/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.3528 - acc: 0.4833 - val_loss: 1.7026 - val_acc: 0.3889\n",
      "\n",
      "Epoch 663/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3451 - acc: 0.5375 - val_loss: 1.6921 - val_acc: 0.4167\n",
      "\n",
      "Epoch 664/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.3976 - acc: 0.5083 - val_loss: 1.6952 - val_acc: 0.3750\n",
      "\n",
      "Epoch 665/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.3713 - acc: 0.5042 - val_loss: 1.6969 - val_acc: 0.4167\n",
      "\n",
      "Epoch 666/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 70us/step - loss: 1.3131 - acc: 0.5542 - val_loss: 1.6972 - val_acc: 0.3889\n",
      "\n",
      "Epoch 667/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.4149 - acc: 0.4542 - val_loss: 1.6877 - val_acc: 0.4028\n",
      "\n",
      "Epoch 668/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.4333 - acc: 0.4417 - val_loss: 1.6908 - val_acc: 0.4028\n",
      "\n",
      "Epoch 669/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.4014 - acc: 0.4917 - val_loss: 1.6926 - val_acc: 0.4028\n",
      "\n",
      "Epoch 670/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.3592 - acc: 0.4750 - val_loss: 1.6940 - val_acc: 0.4028\n",
      "\n",
      "Epoch 671/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2962 - acc: 0.5292 - val_loss: 1.6964 - val_acc: 0.3889\n",
      "\n",
      "Epoch 672/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.4368 - acc: 0.4542 - val_loss: 1.6921 - val_acc: 0.4028\n",
      "\n",
      "Epoch 673/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.4291 - acc: 0.4583 - val_loss: 1.6914 - val_acc: 0.3750\n",
      "\n",
      "Epoch 674/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.3778 - acc: 0.5167 - val_loss: 1.6800 - val_acc: 0.4167\n",
      "\n",
      "Epoch 675/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.3935 - acc: 0.4917 - val_loss: 1.6838 - val_acc: 0.3889\n",
      "\n",
      "Epoch 676/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.3689 - acc: 0.5167 - val_loss: 1.6892 - val_acc: 0.4028\n",
      "\n",
      "Epoch 677/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.4630 - acc: 0.4083 - val_loss: 1.7039 - val_acc: 0.3889\n",
      "\n",
      "Epoch 678/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3715 - acc: 0.5167 - val_loss: 1.6948 - val_acc: 0.4028\n",
      "\n",
      "Epoch 679/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.3593 - acc: 0.4917 - val_loss: 1.6849 - val_acc: 0.3889\n",
      "\n",
      "Epoch 680/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.3907 - acc: 0.5083 - val_loss: 1.6891 - val_acc: 0.4167\n",
      "\n",
      "Epoch 681/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.4000 - acc: 0.4583 - val_loss: 1.6881 - val_acc: 0.4028\n",
      "\n",
      "Epoch 682/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 38us/step - loss: 1.3858 - acc: 0.5042 - val_loss: 1.6856 - val_acc: 0.4028\n",
      "\n",
      "Epoch 683/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 45us/step - loss: 1.3425 - acc: 0.5167 - val_loss: 1.6830 - val_acc: 0.4167\n",
      "\n",
      "Epoch 684/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.3484 - acc: 0.5042 - val_loss: 1.6819 - val_acc: 0.4167\n",
      "\n",
      "Epoch 685/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.3672 - acc: 0.4708 - val_loss: 1.6867 - val_acc: 0.4583\n",
      "\n",
      "Epoch 686/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4654 - acc: 0.4625 - val_loss: 1.6910 - val_acc: 0.4028\n",
      "\n",
      "Epoch 687/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.3404 - acc: 0.5042 - val_loss: 1.6954 - val_acc: 0.4028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 688/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.3598 - acc: 0.4583 - val_loss: 1.6903 - val_acc: 0.4306\n",
      "\n",
      "Epoch 689/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.3309 - acc: 0.5208 - val_loss: 1.6922 - val_acc: 0.4306\n",
      "\n",
      "Epoch 690/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.3125 - acc: 0.4958 - val_loss: 1.6988 - val_acc: 0.4167\n",
      "\n",
      "Epoch 691/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.3308 - acc: 0.5042 - val_loss: 1.7002 - val_acc: 0.4167\n",
      "\n",
      "Epoch 692/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.3848 - acc: 0.4583 - val_loss: 1.6936 - val_acc: 0.4306\n",
      "\n",
      "Epoch 693/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.3276 - acc: 0.4667 - val_loss: 1.6884 - val_acc: 0.4444\n",
      "\n",
      "Epoch 694/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.3464 - acc: 0.4750 - val_loss: 1.6969 - val_acc: 0.4444\n",
      "\n",
      "Epoch 695/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.4161 - acc: 0.4667 - val_loss: 1.6880 - val_acc: 0.4583\n",
      "\n",
      "Epoch 696/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 127us/step - loss: 1.3228 - acc: 0.5167 - val_loss: 1.6916 - val_acc: 0.4167\n",
      "\n",
      "Epoch 697/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.3960 - acc: 0.4917 - val_loss: 1.6917 - val_acc: 0.4306\n",
      "\n",
      "Epoch 698/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.3304 - acc: 0.5000 - val_loss: 1.6940 - val_acc: 0.4028\n",
      "\n",
      "Epoch 699/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.3459 - acc: 0.5208 - val_loss: 1.6896 - val_acc: 0.4167\n",
      "\n",
      "Epoch 700/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.3653 - acc: 0.5583 - val_loss: 1.6862 - val_acc: 0.4444\n",
      "\n",
      "Epoch 701/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.3001 - acc: 0.5167 - val_loss: 1.6867 - val_acc: 0.4306\n",
      "\n",
      "Epoch 702/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.3947 - acc: 0.4833 - val_loss: 1.6912 - val_acc: 0.4444\n",
      "\n",
      "Epoch 703/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.3067 - acc: 0.4958 - val_loss: 1.6919 - val_acc: 0.4306\n",
      "\n",
      "Epoch 704/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.3419 - acc: 0.4875 - val_loss: 1.6872 - val_acc: 0.4028\n",
      "\n",
      "Epoch 705/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.3572 - acc: 0.5125 - val_loss: 1.6854 - val_acc: 0.4444\n",
      "\n",
      "Epoch 706/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3549 - acc: 0.4958 - val_loss: 1.6877 - val_acc: 0.4444\n",
      "\n",
      "Epoch 707/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3356 - acc: 0.5042 - val_loss: 1.6911 - val_acc: 0.4167\n",
      "\n",
      "Epoch 708/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.3572 - acc: 0.5292 - val_loss: 1.6924 - val_acc: 0.4306\n",
      "\n",
      "Epoch 709/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3169 - acc: 0.4833 - val_loss: 1.7000 - val_acc: 0.4167\n",
      "\n",
      "Epoch 710/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.3766 - acc: 0.4667 - val_loss: 1.6944 - val_acc: 0.4444\n",
      "\n",
      "Epoch 711/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.4001 - acc: 0.4583 - val_loss: 1.6950 - val_acc: 0.4306\n",
      "\n",
      "Epoch 712/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.3675 - acc: 0.5083 - val_loss: 1.6904 - val_acc: 0.4306\n",
      "\n",
      "Epoch 713/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.3784 - acc: 0.4917 - val_loss: 1.6939 - val_acc: 0.4167\n",
      "\n",
      "Epoch 714/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.3629 - acc: 0.4833 - val_loss: 1.6963 - val_acc: 0.4306\n",
      "\n",
      "Epoch 715/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 47us/step - loss: 1.3730 - acc: 0.4792 - val_loss: 1.6952 - val_acc: 0.4306\n",
      "\n",
      "Epoch 716/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.3606 - acc: 0.5542 - val_loss: 1.6957 - val_acc: 0.4306\n",
      "\n",
      "Epoch 717/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 1.3694 - acc: 0.4750 - val_loss: 1.6985 - val_acc: 0.4306\n",
      "\n",
      "Epoch 718/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.4146 - acc: 0.4417 - val_loss: 1.6890 - val_acc: 0.4306\n",
      "\n",
      "Epoch 719/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.3051 - acc: 0.5292 - val_loss: 1.6920 - val_acc: 0.4306\n",
      "\n",
      "Epoch 720/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 48us/step - loss: 1.3227 - acc: 0.5083 - val_loss: 1.6971 - val_acc: 0.4167\n",
      "\n",
      "Epoch 721/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.3785 - acc: 0.4958 - val_loss: 1.6968 - val_acc: 0.4167\n",
      "\n",
      "Epoch 722/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.3161 - acc: 0.5333 - val_loss: 1.6939 - val_acc: 0.4306\n",
      "\n",
      "Epoch 723/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.3325 - acc: 0.5000 - val_loss: 1.6966 - val_acc: 0.4167\n",
      "\n",
      "Epoch 724/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.4151 - acc: 0.4708 - val_loss: 1.6934 - val_acc: 0.4167\n",
      "\n",
      "Epoch 725/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.3459 - acc: 0.5208 - val_loss: 1.6956 - val_acc: 0.4167\n",
      "\n",
      "Epoch 726/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.3608 - acc: 0.5125 - val_loss: 1.6953 - val_acc: 0.4028\n",
      "\n",
      "Epoch 727/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.3626 - acc: 0.4917 - val_loss: 1.6898 - val_acc: 0.4306\n",
      "\n",
      "Epoch 728/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.3104 - acc: 0.5167 - val_loss: 1.6946 - val_acc: 0.4028\n",
      "\n",
      "Epoch 729/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.2675 - acc: 0.5750 - val_loss: 1.6978 - val_acc: 0.4167\n",
      "\n",
      "Epoch 730/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.3868 - acc: 0.5083 - val_loss: 1.6966 - val_acc: 0.4167\n",
      "\n",
      "Epoch 731/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.3272 - acc: 0.5167 - val_loss: 1.6950 - val_acc: 0.4167\n",
      "\n",
      "Epoch 732/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 122us/step - loss: 1.3563 - acc: 0.5042 - val_loss: 1.6988 - val_acc: 0.4167\n",
      "\n",
      "Epoch 733/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.3333 - acc: 0.4458 - val_loss: 1.6938 - val_acc: 0.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 734/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3095 - acc: 0.5625 - val_loss: 1.6923 - val_acc: 0.4583\n",
      "\n",
      "Epoch 735/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3096 - acc: 0.5333 - val_loss: 1.6938 - val_acc: 0.4167\n",
      "\n",
      "Epoch 736/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.3686 - acc: 0.4667 - val_loss: 1.6907 - val_acc: 0.4306\n",
      "\n",
      "Epoch 737/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3058 - acc: 0.5167 - val_loss: 1.7034 - val_acc: 0.4167\n",
      "\n",
      "Epoch 738/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.3536 - acc: 0.4792 - val_loss: 1.7043 - val_acc: 0.4167\n",
      "\n",
      "Epoch 739/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.3726 - acc: 0.4750 - val_loss: 1.6926 - val_acc: 0.4306\n",
      "\n",
      "Epoch 740/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 70us/step - loss: 1.3813 - acc: 0.4708 - val_loss: 1.6917 - val_acc: 0.4444\n",
      "\n",
      "Epoch 741/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.3747 - acc: 0.4667 - val_loss: 1.6919 - val_acc: 0.4583\n",
      "\n",
      "Epoch 742/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2995 - acc: 0.5542 - val_loss: 1.6937 - val_acc: 0.4306\n",
      "\n",
      "Epoch 743/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.2870 - acc: 0.4792 - val_loss: 1.6902 - val_acc: 0.4167\n",
      "\n",
      "Epoch 744/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.3450 - acc: 0.4792 - val_loss: 1.6952 - val_acc: 0.4306\n",
      "\n",
      "Epoch 745/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.3237 - acc: 0.5083 - val_loss: 1.6948 - val_acc: 0.4306\n",
      "\n",
      "Epoch 746/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.3669 - acc: 0.4875 - val_loss: 1.6939 - val_acc: 0.4167\n",
      "\n",
      "Epoch 747/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.3980 - acc: 0.4792 - val_loss: 1.6963 - val_acc: 0.4306\n",
      "\n",
      "Epoch 748/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 56us/step - loss: 1.3134 - acc: 0.5000 - val_loss: 1.6876 - val_acc: 0.4306\n",
      "\n",
      "Epoch 749/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2853 - acc: 0.5250 - val_loss: 1.6892 - val_acc: 0.4444\n",
      "\n",
      "Epoch 750/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.2601 - acc: 0.5417 - val_loss: 1.6902 - val_acc: 0.4444\n",
      "\n",
      "Epoch 751/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.3685 - acc: 0.4750 - val_loss: 1.6880 - val_acc: 0.4306\n",
      "\n",
      "Epoch 752/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.3514 - acc: 0.4958 - val_loss: 1.6954 - val_acc: 0.4306\n",
      "\n",
      "Epoch 753/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 1.3922 - acc: 0.4833 - val_loss: 1.6983 - val_acc: 0.4306\n",
      "\n",
      "Epoch 754/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 1.3368 - acc: 0.5458 - val_loss: 1.7032 - val_acc: 0.4167\n",
      "\n",
      "Epoch 755/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.3306 - acc: 0.5000 - val_loss: 1.6963 - val_acc: 0.4306\n",
      "\n",
      "Epoch 756/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.2803 - acc: 0.5208 - val_loss: 1.7001 - val_acc: 0.4306\n",
      "\n",
      "Epoch 757/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.3619 - acc: 0.5000 - val_loss: 1.6953 - val_acc: 0.4444\n",
      "\n",
      "Epoch 758/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.2978 - acc: 0.5083 - val_loss: 1.6938 - val_acc: 0.4444\n",
      "\n",
      "Epoch 759/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 122us/step - loss: 1.3449 - acc: 0.5083 - val_loss: 1.6944 - val_acc: 0.4306\n",
      "\n",
      "Epoch 760/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.3041 - acc: 0.5125 - val_loss: 1.7021 - val_acc: 0.4306\n",
      "\n",
      "Epoch 761/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.3642 - acc: 0.4875 - val_loss: 1.6966 - val_acc: 0.4444\n",
      "\n",
      "Epoch 762/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.2959 - acc: 0.5250 - val_loss: 1.7017 - val_acc: 0.4306\n",
      "\n",
      "Epoch 763/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.2974 - acc: 0.5292 - val_loss: 1.6949 - val_acc: 0.4583\n",
      "\n",
      "Epoch 764/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.3114 - acc: 0.5250 - val_loss: 1.6928 - val_acc: 0.4444\n",
      "\n",
      "Epoch 765/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.3122 - acc: 0.5083 - val_loss: 1.6857 - val_acc: 0.4583\n",
      "\n",
      "Epoch 766/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3770 - acc: 0.5000 - val_loss: 1.6919 - val_acc: 0.4861\n",
      "\n",
      "Epoch 767/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3662 - acc: 0.4708 - val_loss: 1.6895 - val_acc: 0.4306\n",
      "\n",
      "Epoch 768/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.3316 - acc: 0.5542 - val_loss: 1.6917 - val_acc: 0.4444\n",
      "\n",
      "Epoch 769/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.3822 - acc: 0.4667 - val_loss: 1.6938 - val_acc: 0.4444\n",
      "\n",
      "Epoch 770/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 106us/step - loss: 1.3624 - acc: 0.5000 - val_loss: 1.6906 - val_acc: 0.4306\n",
      "\n",
      "Epoch 771/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.3184 - acc: 0.5500 - val_loss: 1.6954 - val_acc: 0.4306\n",
      "\n",
      "Epoch 772/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.3509 - acc: 0.4792 - val_loss: 1.6909 - val_acc: 0.4444\n",
      "\n",
      "Epoch 773/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.2647 - acc: 0.5167 - val_loss: 1.6966 - val_acc: 0.4444\n",
      "\n",
      "Epoch 774/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.3220 - acc: 0.5333 - val_loss: 1.6934 - val_acc: 0.4306\n",
      "\n",
      "Epoch 775/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3039 - acc: 0.5292 - val_loss: 1.6907 - val_acc: 0.4444\n",
      "\n",
      "Epoch 776/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3527 - acc: 0.4958 - val_loss: 1.6835 - val_acc: 0.4444\n",
      "\n",
      "Epoch 777/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.2701 - acc: 0.5333 - val_loss: 1.6885 - val_acc: 0.4444\n",
      "\n",
      "Epoch 778/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.3042 - acc: 0.4875 - val_loss: 1.6899 - val_acc: 0.4444\n",
      "\n",
      "Epoch 779/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.3864 - acc: 0.4833 - val_loss: 1.6964 - val_acc: 0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 780/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.3285 - acc: 0.4917 - val_loss: 1.6909 - val_acc: 0.4444\n",
      "\n",
      "Epoch 781/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 45us/step - loss: 1.3147 - acc: 0.5292 - val_loss: 1.6944 - val_acc: 0.4444\n",
      "\n",
      "Epoch 782/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.3014 - acc: 0.4917 - val_loss: 1.6883 - val_acc: 0.4444\n",
      "\n",
      "Epoch 783/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.3217 - acc: 0.4833 - val_loss: 1.6916 - val_acc: 0.4444\n",
      "\n",
      "Epoch 784/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.3838 - acc: 0.4875 - val_loss: 1.6873 - val_acc: 0.4444\n",
      "\n",
      "Epoch 785/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.3146 - acc: 0.5000 - val_loss: 1.6906 - val_acc: 0.4444\n",
      "\n",
      "Epoch 786/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 39us/step - loss: 1.3354 - acc: 0.4917 - val_loss: 1.6996 - val_acc: 0.4306\n",
      "\n",
      "Epoch 787/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 135us/step - loss: 1.3285 - acc: 0.4750 - val_loss: 1.6899 - val_acc: 0.4444\n",
      "\n",
      "Epoch 788/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.3681 - acc: 0.4917 - val_loss: 1.6899 - val_acc: 0.4444\n",
      "\n",
      "Epoch 789/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.2870 - acc: 0.5208 - val_loss: 1.6853 - val_acc: 0.4444\n",
      "\n",
      "Epoch 790/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 1.3682 - acc: 0.4750 - val_loss: 1.6872 - val_acc: 0.4444\n",
      "\n",
      "Epoch 791/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.3408 - acc: 0.5000 - val_loss: 1.6877 - val_acc: 0.4722\n",
      "\n",
      "Epoch 792/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.3009 - acc: 0.5000 - val_loss: 1.6887 - val_acc: 0.4444\n",
      "\n",
      "Epoch 793/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.3846 - acc: 0.4875 - val_loss: 1.6885 - val_acc: 0.4167\n",
      "\n",
      "Epoch 794/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2811 - acc: 0.4875 - val_loss: 1.6848 - val_acc: 0.4444\n",
      "\n",
      "Epoch 795/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.2771 - acc: 0.5292 - val_loss: 1.6885 - val_acc: 0.4444\n",
      "\n",
      "Epoch 796/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.3249 - acc: 0.5208 - val_loss: 1.6959 - val_acc: 0.4444\n",
      "\n",
      "Epoch 797/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.2956 - acc: 0.5208 - val_loss: 1.6928 - val_acc: 0.4444\n",
      "\n",
      "Epoch 798/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.2096 - acc: 0.5583 - val_loss: 1.6943 - val_acc: 0.4583\n",
      "\n",
      "Epoch 799/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2656 - acc: 0.5375 - val_loss: 1.6899 - val_acc: 0.4722\n",
      "\n",
      "Epoch 800/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2980 - acc: 0.5250 - val_loss: 1.6918 - val_acc: 0.4444\n",
      "\n",
      "Epoch 801/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.2641 - acc: 0.5542 - val_loss: 1.6920 - val_acc: 0.4861\n",
      "\n",
      "Epoch 802/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2253 - acc: 0.5625 - val_loss: 1.6907 - val_acc: 0.4444\n",
      "\n",
      "Epoch 803/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3577 - acc: 0.4958 - val_loss: 1.7054 - val_acc: 0.4306\n",
      "\n",
      "Epoch 804/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.3161 - acc: 0.5083 - val_loss: 1.6960 - val_acc: 0.4722\n",
      "\n",
      "Epoch 805/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.3236 - acc: 0.4875 - val_loss: 1.6897 - val_acc: 0.4444\n",
      "\n",
      "Epoch 806/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.2537 - acc: 0.5375 - val_loss: 1.6930 - val_acc: 0.4583\n",
      "\n",
      "Epoch 807/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.3104 - acc: 0.5000 - val_loss: 1.6936 - val_acc: 0.4583\n",
      "\n",
      "Epoch 808/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2971 - acc: 0.5042 - val_loss: 1.6921 - val_acc: 0.4444\n",
      "\n",
      "Epoch 809/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2778 - acc: 0.5250 - val_loss: 1.6887 - val_acc: 0.4861\n",
      "\n",
      "Epoch 810/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2847 - acc: 0.5208 - val_loss: 1.6890 - val_acc: 0.4722\n",
      "\n",
      "Epoch 811/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.3156 - acc: 0.5208 - val_loss: 1.6916 - val_acc: 0.4444\n",
      "\n",
      "Epoch 812/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.3217 - acc: 0.5125 - val_loss: 1.6924 - val_acc: 0.4722\n",
      "\n",
      "Epoch 813/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 60us/step - loss: 1.3199 - acc: 0.5417 - val_loss: 1.6906 - val_acc: 0.4306\n",
      "\n",
      "Epoch 814/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 1.2772 - acc: 0.5375 - val_loss: 1.6984 - val_acc: 0.4444\n",
      "\n",
      "Epoch 815/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.3194 - acc: 0.5125 - val_loss: 1.6975 - val_acc: 0.4861\n",
      "\n",
      "Epoch 816/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2698 - acc: 0.5167 - val_loss: 1.6958 - val_acc: 0.4444\n",
      "\n",
      "Epoch 817/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.3404 - acc: 0.4875 - val_loss: 1.6940 - val_acc: 0.4583\n",
      "\n",
      "Epoch 818/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 42us/step - loss: 1.2876 - acc: 0.5375 - val_loss: 1.6891 - val_acc: 0.4583\n",
      "\n",
      "Epoch 819/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 55us/step - loss: 1.3533 - acc: 0.5125 - val_loss: 1.6953 - val_acc: 0.4583\n",
      "\n",
      "Epoch 820/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.2731 - acc: 0.5583 - val_loss: 1.6994 - val_acc: 0.4444\n",
      "\n",
      "Epoch 821/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.3090 - acc: 0.5042 - val_loss: 1.6931 - val_acc: 0.4722\n",
      "\n",
      "Epoch 822/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.2584 - acc: 0.5333 - val_loss: 1.6944 - val_acc: 0.4722\n",
      "\n",
      "Epoch 823/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.2907 - acc: 0.5375 - val_loss: 1.6960 - val_acc: 0.4444\n",
      "\n",
      "Epoch 824/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.2995 - acc: 0.5292 - val_loss: 1.6985 - val_acc: 0.4583\n",
      "\n",
      "Epoch 825/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.3317 - acc: 0.5042 - val_loss: 1.6911 - val_acc: 0.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 826/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 1.2512 - acc: 0.5417 - val_loss: 1.6931 - val_acc: 0.4444\n",
      "\n",
      "Epoch 827/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.2963 - acc: 0.5042 - val_loss: 1.6875 - val_acc: 0.4583\n",
      "\n",
      "Epoch 828/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.3243 - acc: 0.5417 - val_loss: 1.6876 - val_acc: 0.4444\n",
      "\n",
      "Epoch 829/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.3154 - acc: 0.5083 - val_loss: 1.6929 - val_acc: 0.4444\n",
      "\n",
      "Epoch 830/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3224 - acc: 0.5083 - val_loss: 1.6871 - val_acc: 0.4444\n",
      "\n",
      "Epoch 831/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3094 - acc: 0.5125 - val_loss: 1.6851 - val_acc: 0.4444\n",
      "\n",
      "Epoch 832/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.2287 - acc: 0.5542 - val_loss: 1.6864 - val_acc: 0.4444\n",
      "\n",
      "Epoch 833/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2318 - acc: 0.5708 - val_loss: 1.6880 - val_acc: 0.4444\n",
      "\n",
      "Epoch 834/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.3126 - acc: 0.4958 - val_loss: 1.6900 - val_acc: 0.4583\n",
      "\n",
      "Epoch 835/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.3389 - acc: 0.4750 - val_loss: 1.6884 - val_acc: 0.4722\n",
      "\n",
      "Epoch 836/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.3409 - acc: 0.4833 - val_loss: 1.6846 - val_acc: 0.4861\n",
      "\n",
      "Epoch 837/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 70us/step - loss: 1.2584 - acc: 0.5208 - val_loss: 1.6888 - val_acc: 0.4861\n",
      "\n",
      "Epoch 838/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.3107 - acc: 0.5458 - val_loss: 1.6901 - val_acc: 0.4583\n",
      "\n",
      "Epoch 839/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2941 - acc: 0.5542 - val_loss: 1.6833 - val_acc: 0.4722\n",
      "\n",
      "Epoch 840/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2711 - acc: 0.5208 - val_loss: 1.6908 - val_acc: 0.4583\n",
      "\n",
      "Epoch 841/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2598 - acc: 0.5333 - val_loss: 1.6897 - val_acc: 0.4722\n",
      "\n",
      "Epoch 842/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.3188 - acc: 0.5333 - val_loss: 1.6937 - val_acc: 0.4444\n",
      "\n",
      "Epoch 843/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2687 - acc: 0.5792 - val_loss: 1.6908 - val_acc: 0.5000\n",
      "\n",
      "Epoch 844/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2998 - acc: 0.4750 - val_loss: 1.6948 - val_acc: 0.4583\n",
      "\n",
      "Epoch 845/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2975 - acc: 0.5208 - val_loss: 1.6908 - val_acc: 0.4583\n",
      "\n",
      "Epoch 846/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 44us/step - loss: 1.2799 - acc: 0.5208 - val_loss: 1.6896 - val_acc: 0.4722\n",
      "\n",
      "Epoch 847/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2548 - acc: 0.5458 - val_loss: 1.6952 - val_acc: 0.4444\n",
      "\n",
      "Epoch 848/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2913 - acc: 0.5375 - val_loss: 1.6888 - val_acc: 0.4583\n",
      "\n",
      "Epoch 849/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.2363 - acc: 0.5667 - val_loss: 1.6945 - val_acc: 0.4444\n",
      "\n",
      "Epoch 850/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.2955 - acc: 0.5292 - val_loss: 1.7008 - val_acc: 0.4306\n",
      "\n",
      "Epoch 851/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.3130 - acc: 0.5083 - val_loss: 1.6882 - val_acc: 0.4583\n",
      "\n",
      "Epoch 852/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 65us/step - loss: 1.2400 - acc: 0.5083 - val_loss: 1.6906 - val_acc: 0.4583\n",
      "\n",
      "Epoch 853/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.3125 - acc: 0.5083 - val_loss: 1.6887 - val_acc: 0.4444\n",
      "\n",
      "Epoch 854/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 128us/step - loss: 1.2818 - acc: 0.5208 - val_loss: 1.6873 - val_acc: 0.4861\n",
      "\n",
      "Epoch 855/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.3044 - acc: 0.5292 - val_loss: 1.6940 - val_acc: 0.4444\n",
      "\n",
      "Epoch 856/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 1.3236 - acc: 0.5042 - val_loss: 1.6940 - val_acc: 0.4444\n",
      "\n",
      "Epoch 857/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3042 - acc: 0.5250 - val_loss: 1.6909 - val_acc: 0.4583\n",
      "\n",
      "Epoch 858/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2838 - acc: 0.5250 - val_loss: 1.6876 - val_acc: 0.4444\n",
      "\n",
      "Epoch 859/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.3179 - acc: 0.5167 - val_loss: 1.6934 - val_acc: 0.4306\n",
      "\n",
      "Epoch 860/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.2867 - acc: 0.5625 - val_loss: 1.6955 - val_acc: 0.4444\n",
      "\n",
      "Epoch 861/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.3081 - acc: 0.5000 - val_loss: 1.6930 - val_acc: 0.4444\n",
      "\n",
      "Epoch 862/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.2407 - acc: 0.5292 - val_loss: 1.6964 - val_acc: 0.4444\n",
      "\n",
      "Epoch 863/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2667 - acc: 0.5250 - val_loss: 1.6870 - val_acc: 0.4583\n",
      "\n",
      "Epoch 864/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.2898 - acc: 0.5250 - val_loss: 1.6917 - val_acc: 0.4444\n",
      "\n",
      "Epoch 865/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.3245 - acc: 0.5417 - val_loss: 1.6962 - val_acc: 0.4444\n",
      "\n",
      "Epoch 866/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2322 - acc: 0.5375 - val_loss: 1.6945 - val_acc: 0.4722\n",
      "\n",
      "Epoch 867/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2024 - acc: 0.5375 - val_loss: 1.6916 - val_acc: 0.4722\n",
      "\n",
      "Epoch 868/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2839 - acc: 0.5292 - val_loss: 1.6875 - val_acc: 0.5000\n",
      "\n",
      "Epoch 869/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.3006 - acc: 0.5042 - val_loss: 1.6865 - val_acc: 0.4861\n",
      "\n",
      "Epoch 870/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2630 - acc: 0.4917 - val_loss: 1.6869 - val_acc: 0.4861\n",
      "\n",
      "Epoch 871/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.2698 - acc: 0.5125 - val_loss: 1.6884 - val_acc: 0.4861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 872/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2908 - acc: 0.5250 - val_loss: 1.6898 - val_acc: 0.4722\n",
      "\n",
      "Epoch 873/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2309 - acc: 0.5375 - val_loss: 1.6917 - val_acc: 0.4722\n",
      "\n",
      "Epoch 874/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2774 - acc: 0.5167 - val_loss: 1.6887 - val_acc: 0.4722\n",
      "\n",
      "Epoch 875/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.3010 - acc: 0.4917 - val_loss: 1.6939 - val_acc: 0.4583\n",
      "\n",
      "Epoch 876/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2775 - acc: 0.5333 - val_loss: 1.6915 - val_acc: 0.4722\n",
      "\n",
      "Epoch 877/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2896 - acc: 0.5250 - val_loss: 1.6892 - val_acc: 0.4583\n",
      "\n",
      "Epoch 878/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2586 - acc: 0.5792 - val_loss: 1.6886 - val_acc: 0.4583\n",
      "\n",
      "Epoch 879/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 67us/step - loss: 1.2359 - acc: 0.5375 - val_loss: 1.6904 - val_acc: 0.4861\n",
      "\n",
      "Epoch 880/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2714 - acc: 0.5417 - val_loss: 1.6893 - val_acc: 0.5000\n",
      "\n",
      "Epoch 881/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 36us/step - loss: 1.2642 - acc: 0.5667 - val_loss: 1.6944 - val_acc: 0.4722\n",
      "\n",
      "Epoch 882/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.3196 - acc: 0.4958 - val_loss: 1.6873 - val_acc: 0.4861\n",
      "\n",
      "Epoch 883/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2667 - acc: 0.5042 - val_loss: 1.6867 - val_acc: 0.4722\n",
      "\n",
      "Epoch 884/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.3264 - acc: 0.5083 - val_loss: 1.6897 - val_acc: 0.4722\n",
      "\n",
      "Epoch 885/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 60us/step - loss: 1.2893 - acc: 0.4958 - val_loss: 1.6875 - val_acc: 0.4444\n",
      "\n",
      "Epoch 886/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 1.2591 - acc: 0.5333 - val_loss: 1.6874 - val_acc: 0.4583\n",
      "\n",
      "Epoch 887/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 128us/step - loss: 1.2552 - acc: 0.5417 - val_loss: 1.6983 - val_acc: 0.4722\n",
      "\n",
      "Epoch 888/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.2384 - acc: 0.5000 - val_loss: 1.6989 - val_acc: 0.4861\n",
      "\n",
      "Epoch 889/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.2851 - acc: 0.5083 - val_loss: 1.6971 - val_acc: 0.4722\n",
      "\n",
      "Epoch 890/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.2537 - acc: 0.5417 - val_loss: 1.6978 - val_acc: 0.4861\n",
      "\n",
      "Epoch 891/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 110us/step - loss: 1.3391 - acc: 0.4875 - val_loss: 1.6936 - val_acc: 0.4722\n",
      "\n",
      "Epoch 892/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.2756 - acc: 0.4958 - val_loss: 1.6916 - val_acc: 0.4722\n",
      "\n",
      "Epoch 893/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.3304 - acc: 0.5000 - val_loss: 1.6945 - val_acc: 0.4583\n",
      "\n",
      "Epoch 894/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.2784 - acc: 0.4667 - val_loss: 1.6949 - val_acc: 0.4583\n",
      "\n",
      "Epoch 895/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.3245 - acc: 0.5208 - val_loss: 1.6983 - val_acc: 0.4583\n",
      "\n",
      "Epoch 896/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.2640 - acc: 0.4958 - val_loss: 1.6920 - val_acc: 0.4722\n",
      "\n",
      "Epoch 897/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2642 - acc: 0.5167 - val_loss: 1.6961 - val_acc: 0.4583\n",
      "\n",
      "Epoch 898/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2589 - acc: 0.5292 - val_loss: 1.6947 - val_acc: 0.4583\n",
      "\n",
      "Epoch 899/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2938 - acc: 0.5208 - val_loss: 1.6928 - val_acc: 0.4861\n",
      "\n",
      "Epoch 900/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.2604 - acc: 0.5125 - val_loss: 1.6936 - val_acc: 0.4861\n",
      "\n",
      "Epoch 901/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.2228 - acc: 0.5417 - val_loss: 1.6998 - val_acc: 0.4722\n",
      "\n",
      "Epoch 902/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2700 - acc: 0.5125 - val_loss: 1.6909 - val_acc: 0.4583\n",
      "\n",
      "Epoch 903/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.2405 - acc: 0.5375 - val_loss: 1.6957 - val_acc: 0.4583\n",
      "\n",
      "Epoch 904/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.2404 - acc: 0.5458 - val_loss: 1.6958 - val_acc: 0.4722\n",
      "\n",
      "Epoch 905/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.2086 - acc: 0.5375 - val_loss: 1.6933 - val_acc: 0.4722\n",
      "\n",
      "Epoch 906/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2381 - acc: 0.5625 - val_loss: 1.6930 - val_acc: 0.4861\n",
      "\n",
      "Epoch 907/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2466 - acc: 0.5208 - val_loss: 1.7006 - val_acc: 0.4583\n",
      "\n",
      "Epoch 908/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2195 - acc: 0.5292 - val_loss: 1.6981 - val_acc: 0.4583\n",
      "\n",
      "Epoch 909/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2082 - acc: 0.5417 - val_loss: 1.6959 - val_acc: 0.4583\n",
      "\n",
      "Epoch 910/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2303 - acc: 0.5125 - val_loss: 1.6911 - val_acc: 0.4722\n",
      "\n",
      "Epoch 911/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2702 - acc: 0.5458 - val_loss: 1.6989 - val_acc: 0.4583\n",
      "\n",
      "Epoch 912/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2841 - acc: 0.5333 - val_loss: 1.6950 - val_acc: 0.4722\n",
      "\n",
      "Epoch 913/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 54us/step - loss: 1.2488 - acc: 0.5375 - val_loss: 1.6934 - val_acc: 0.4722\n",
      "\n",
      "Epoch 914/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.2171 - acc: 0.5458 - val_loss: 1.6989 - val_acc: 0.4722\n",
      "\n",
      "Epoch 915/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 62us/step - loss: 1.2375 - acc: 0.5208 - val_loss: 1.7022 - val_acc: 0.5000\n",
      "\n",
      "Epoch 916/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.2971 - acc: 0.5125 - val_loss: 1.6930 - val_acc: 0.5000\n",
      "\n",
      "Epoch 917/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.2626 - acc: 0.5250 - val_loss: 1.7015 - val_acc: 0.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 918/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.1962 - acc: 0.5250 - val_loss: 1.6969 - val_acc: 0.5000\n",
      "\n",
      "Epoch 919/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.3196 - acc: 0.5000 - val_loss: 1.7026 - val_acc: 0.5000\n",
      "\n",
      "Epoch 920/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 1.2572 - acc: 0.5042 - val_loss: 1.7012 - val_acc: 0.5139\n",
      "\n",
      "Epoch 921/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.2747 - acc: 0.4958 - val_loss: 1.7012 - val_acc: 0.4722\n",
      "\n",
      "Epoch 922/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.2593 - acc: 0.5167 - val_loss: 1.7112 - val_acc: 0.5139\n",
      "\n",
      "Epoch 923/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 111us/step - loss: 1.2024 - acc: 0.5375 - val_loss: 1.7118 - val_acc: 0.4722\n",
      "\n",
      "Epoch 924/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.2912 - acc: 0.5292 - val_loss: 1.7090 - val_acc: 0.4722\n",
      "\n",
      "Epoch 925/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 112us/step - loss: 1.3080 - acc: 0.5167 - val_loss: 1.7031 - val_acc: 0.4861\n",
      "\n",
      "Epoch 926/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 109us/step - loss: 1.2933 - acc: 0.5042 - val_loss: 1.7037 - val_acc: 0.4722\n",
      "\n",
      "Epoch 927/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.2474 - acc: 0.5458 - val_loss: 1.7100 - val_acc: 0.4583\n",
      "\n",
      "Epoch 928/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 122us/step - loss: 1.2516 - acc: 0.5417 - val_loss: 1.7061 - val_acc: 0.4861\n",
      "\n",
      "Epoch 929/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 106us/step - loss: 1.2020 - acc: 0.5333 - val_loss: 1.7123 - val_acc: 0.4583\n",
      "\n",
      "Epoch 930/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2393 - acc: 0.5333 - val_loss: 1.7089 - val_acc: 0.4722\n",
      "\n",
      "Epoch 931/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2682 - acc: 0.5292 - val_loss: 1.7040 - val_acc: 0.4722\n",
      "\n",
      "Epoch 932/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2529 - acc: 0.5333 - val_loss: 1.6969 - val_acc: 0.4722\n",
      "\n",
      "Epoch 933/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.3134 - acc: 0.5083 - val_loss: 1.7005 - val_acc: 0.4722\n",
      "\n",
      "Epoch 934/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.2950 - acc: 0.4917 - val_loss: 1.6984 - val_acc: 0.4583\n",
      "\n",
      "Epoch 935/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 69us/step - loss: 1.2580 - acc: 0.5208 - val_loss: 1.6996 - val_acc: 0.4861\n",
      "\n",
      "Epoch 936/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.2222 - acc: 0.5667 - val_loss: 1.7071 - val_acc: 0.4583\n",
      "\n",
      "Epoch 937/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.2658 - acc: 0.5125 - val_loss: 1.7095 - val_acc: 0.4583\n",
      "\n",
      "Epoch 938/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.2915 - acc: 0.5292 - val_loss: 1.7084 - val_acc: 0.4583\n",
      "\n",
      "Epoch 939/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2706 - acc: 0.5458 - val_loss: 1.7057 - val_acc: 0.4722\n",
      "\n",
      "Epoch 940/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2808 - acc: 0.5292 - val_loss: 1.7012 - val_acc: 0.4722\n",
      "\n",
      "Epoch 941/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.1870 - acc: 0.5500 - val_loss: 1.7042 - val_acc: 0.5000\n",
      "\n",
      "Epoch 942/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2983 - acc: 0.5167 - val_loss: 1.7078 - val_acc: 0.4583\n",
      "\n",
      "Epoch 943/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2188 - acc: 0.5292 - val_loss: 1.7084 - val_acc: 0.4722\n",
      "\n",
      "Epoch 944/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 92us/step - loss: 1.1947 - acc: 0.5250 - val_loss: 1.7078 - val_acc: 0.4722\n",
      "\n",
      "Epoch 945/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 68us/step - loss: 1.2494 - acc: 0.5417 - val_loss: 1.7021 - val_acc: 0.4861\n",
      "\n",
      "Epoch 946/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2550 - acc: 0.4875 - val_loss: 1.7025 - val_acc: 0.5000\n",
      "\n",
      "Epoch 947/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 61us/step - loss: 1.2159 - acc: 0.5667 - val_loss: 1.7000 - val_acc: 0.4861\n",
      "\n",
      "Epoch 948/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 52us/step - loss: 1.2998 - acc: 0.5375 - val_loss: 1.7064 - val_acc: 0.5000\n",
      "\n",
      "Epoch 949/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.2780 - acc: 0.5125 - val_loss: 1.7081 - val_acc: 0.4583\n",
      "\n",
      "Epoch 950/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2599 - acc: 0.5708 - val_loss: 1.7049 - val_acc: 0.4722\n",
      "\n",
      "Epoch 951/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.2215 - acc: 0.5208 - val_loss: 1.7085 - val_acc: 0.4722\n",
      "\n",
      "Epoch 952/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 28us/step - loss: 1.2643 - acc: 0.5208 - val_loss: 1.7103 - val_acc: 0.4722\n",
      "\n",
      "Epoch 953/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.1749 - acc: 0.5542 - val_loss: 1.7114 - val_acc: 0.4861\n",
      "\n",
      "Epoch 954/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.2202 - acc: 0.5667 - val_loss: 1.7127 - val_acc: 0.4583\n",
      "\n",
      "Epoch 955/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.2722 - acc: 0.5417 - val_loss: 1.7091 - val_acc: 0.4722\n",
      "\n",
      "Epoch 956/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 1.2496 - acc: 0.5250 - val_loss: 1.7057 - val_acc: 0.4583\n",
      "\n",
      "Epoch 957/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.2562 - acc: 0.5292 - val_loss: 1.7029 - val_acc: 0.4583\n",
      "\n",
      "Epoch 958/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.2698 - acc: 0.5583 - val_loss: 1.7018 - val_acc: 0.4722\n",
      "\n",
      "Epoch 959/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.2143 - acc: 0.5458 - val_loss: 1.7005 - val_acc: 0.4583\n",
      "\n",
      "Epoch 960/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.2903 - acc: 0.5500 - val_loss: 1.7030 - val_acc: 0.4722\n",
      "\n",
      "Epoch 961/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 124us/step - loss: 1.2710 - acc: 0.5167 - val_loss: 1.7038 - val_acc: 0.4583\n",
      "\n",
      "Epoch 962/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.2443 - acc: 0.5667 - val_loss: 1.7045 - val_acc: 0.4583\n",
      "\n",
      "Epoch 963/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.2919 - acc: 0.5208 - val_loss: 1.7044 - val_acc: 0.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 964/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.2435 - acc: 0.5625 - val_loss: 1.7056 - val_acc: 0.4722\n",
      "\n",
      "Epoch 965/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.3131 - acc: 0.5083 - val_loss: 1.7001 - val_acc: 0.4722\n",
      "\n",
      "Epoch 966/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2224 - acc: 0.5333 - val_loss: 1.6961 - val_acc: 0.4722\n",
      "\n",
      "Epoch 967/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.2183 - acc: 0.5542 - val_loss: 1.7012 - val_acc: 0.4722\n",
      "\n",
      "Epoch 968/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2358 - acc: 0.5208 - val_loss: 1.7025 - val_acc: 0.4583\n",
      "\n",
      "Epoch 969/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2244 - acc: 0.5167 - val_loss: 1.7047 - val_acc: 0.4583\n",
      "\n",
      "Epoch 970/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2758 - acc: 0.5042 - val_loss: 1.7024 - val_acc: 0.4722\n",
      "\n",
      "Epoch 971/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.3001 - acc: 0.5042 - val_loss: 1.7035 - val_acc: 0.4722\n",
      "\n",
      "Epoch 972/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2794 - acc: 0.5333 - val_loss: 1.7111 - val_acc: 0.4722\n",
      "\n",
      "Epoch 973/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.2480 - acc: 0.5208 - val_loss: 1.7131 - val_acc: 0.4583\n",
      "\n",
      "Epoch 974/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2510 - acc: 0.5125 - val_loss: 1.7031 - val_acc: 0.4722\n",
      "\n",
      "Epoch 975/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2345 - acc: 0.5208 - val_loss: 1.7065 - val_acc: 0.4583\n",
      "\n",
      "Epoch 976/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2798 - acc: 0.5208 - val_loss: 1.7026 - val_acc: 0.4722\n",
      "\n",
      "Epoch 977/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2852 - acc: 0.5625 - val_loss: 1.7041 - val_acc: 0.4583\n",
      "\n",
      "Epoch 978/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2757 - acc: 0.5417 - val_loss: 1.7077 - val_acc: 0.4444\n",
      "\n",
      "Epoch 979/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 45us/step - loss: 1.2304 - acc: 0.5542 - val_loss: 1.7043 - val_acc: 0.4583\n",
      "\n",
      "Epoch 980/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.1708 - acc: 0.5750 - val_loss: 1.7084 - val_acc: 0.4861\n",
      "\n",
      "Epoch 981/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2767 - acc: 0.5458 - val_loss: 1.7073 - val_acc: 0.4583\n",
      "\n",
      "Epoch 982/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2088 - acc: 0.5583 - val_loss: 1.7017 - val_acc: 0.4722\n",
      "\n",
      "Epoch 983/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2445 - acc: 0.5375 - val_loss: 1.7011 - val_acc: 0.4722\n",
      "\n",
      "Epoch 984/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2203 - acc: 0.5458 - val_loss: 1.7029 - val_acc: 0.4861\n",
      "\n",
      "Epoch 985/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2423 - acc: 0.5542 - val_loss: 1.7076 - val_acc: 0.4583\n",
      "\n",
      "Epoch 986/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 1.1881 - acc: 0.5500 - val_loss: 1.7116 - val_acc: 0.4583\n",
      "\n",
      "Epoch 987/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.2348 - acc: 0.5375 - val_loss: 1.7188 - val_acc: 0.4583\n",
      "\n",
      "Epoch 988/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.2681 - acc: 0.5208 - val_loss: 1.7112 - val_acc: 0.4583\n",
      "\n",
      "Epoch 989/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.2127 - acc: 0.5333 - val_loss: 1.7086 - val_acc: 0.4722\n",
      "\n",
      "Epoch 990/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 125us/step - loss: 1.2755 - acc: 0.4833 - val_loss: 1.7033 - val_acc: 0.4861\n",
      "\n",
      "Epoch 991/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.1886 - acc: 0.5458 - val_loss: 1.7061 - val_acc: 0.4861\n",
      "\n",
      "Epoch 992/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.1685 - acc: 0.6000 - val_loss: 1.7059 - val_acc: 0.4722\n",
      "\n",
      "Epoch 993/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2476 - acc: 0.5042 - val_loss: 1.7113 - val_acc: 0.5000\n",
      "\n",
      "Epoch 994/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2137 - acc: 0.5500 - val_loss: 1.7138 - val_acc: 0.4583\n",
      "\n",
      "Epoch 995/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.2385 - acc: 0.5583 - val_loss: 1.7127 - val_acc: 0.4583\n",
      "\n",
      "Epoch 996/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2644 - acc: 0.5375 - val_loss: 1.7071 - val_acc: 0.4722\n",
      "\n",
      "Epoch 997/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.3115 - acc: 0.5250 - val_loss: 1.7070 - val_acc: 0.4444\n",
      "\n",
      "Epoch 998/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2575 - acc: 0.5417 - val_loss: 1.7099 - val_acc: 0.4861\n",
      "\n",
      "Epoch 999/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.2279 - acc: 0.5500 - val_loss: 1.7110 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1000/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.2106 - acc: 0.5375 - val_loss: 1.7121 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1001/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.2248 - acc: 0.5250 - val_loss: 1.7100 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1002/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2476 - acc: 0.5375 - val_loss: 1.7095 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1003/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.2075 - acc: 0.5583 - val_loss: 1.7026 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1004/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.1971 - acc: 0.5625 - val_loss: 1.7044 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1005/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.3127 - acc: 0.4958 - val_loss: 1.7036 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1006/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.2385 - acc: 0.5208 - val_loss: 1.7077 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1007/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.2842 - acc: 0.5083 - val_loss: 1.7088 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1008/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2026 - acc: 0.5625 - val_loss: 1.7131 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1009/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2897 - acc: 0.5208 - val_loss: 1.7099 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1010/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 66us/step - loss: 1.3014 - acc: 0.4833 - val_loss: 1.7082 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1011/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2300 - acc: 0.5208 - val_loss: 1.7083 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1012/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2387 - acc: 0.5042 - val_loss: 1.7073 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1013/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 70us/step - loss: 1.2773 - acc: 0.5292 - val_loss: 1.7084 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1014/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 1.2007 - acc: 0.5292 - val_loss: 1.7116 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1015/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.2308 - acc: 0.5292 - val_loss: 1.7055 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1016/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.2611 - acc: 0.5375 - val_loss: 1.7063 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1017/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.2349 - acc: 0.5917 - val_loss: 1.7115 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1018/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.3373 - acc: 0.4500 - val_loss: 1.7079 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1019/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2063 - acc: 0.5625 - val_loss: 1.7114 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1020/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 56us/step - loss: 1.2792 - acc: 0.5125 - val_loss: 1.7076 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1021/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.2884 - acc: 0.5375 - val_loss: 1.7051 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1022/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.2296 - acc: 0.5375 - val_loss: 1.7082 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1023/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.2213 - acc: 0.5292 - val_loss: 1.7153 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1024/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.1632 - acc: 0.5875 - val_loss: 1.7137 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1025/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.2662 - acc: 0.5208 - val_loss: 1.7138 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1026/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.3117 - acc: 0.5000 - val_loss: 1.7118 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1027/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 119us/step - loss: 1.1618 - acc: 0.5583 - val_loss: 1.7061 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1028/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.2975 - acc: 0.5042 - val_loss: 1.7098 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1029/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.2371 - acc: 0.5125 - val_loss: 1.7176 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1030/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.2056 - acc: 0.5625 - val_loss: 1.7236 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1031/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 125us/step - loss: 1.2447 - acc: 0.5292 - val_loss: 1.7225 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1032/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.1978 - acc: 0.5792 - val_loss: 1.7229 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1033/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2503 - acc: 0.5250 - val_loss: 1.7224 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1034/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2550 - acc: 0.5542 - val_loss: 1.7191 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1035/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 89us/step - loss: 1.2203 - acc: 0.5375 - val_loss: 1.7187 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1036/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2700 - acc: 0.5083 - val_loss: 1.7207 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1037/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.2384 - acc: 0.5458 - val_loss: 1.7226 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1038/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2249 - acc: 0.5125 - val_loss: 1.7189 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1039/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2305 - acc: 0.4958 - val_loss: 1.7218 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1040/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.1992 - acc: 0.5583 - val_loss: 1.7214 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1041/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2759 - acc: 0.5083 - val_loss: 1.7225 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1042/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.2367 - acc: 0.5333 - val_loss: 1.7246 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1043/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.1933 - acc: 0.5917 - val_loss: 1.7291 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1044/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2161 - acc: 0.5167 - val_loss: 1.7228 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1045/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2449 - acc: 0.5083 - val_loss: 1.7256 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1046/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2337 - acc: 0.5417 - val_loss: 1.7234 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1047/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2342 - acc: 0.4958 - val_loss: 1.7193 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1048/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.2290 - acc: 0.5583 - val_loss: 1.7247 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1049/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2673 - acc: 0.5125 - val_loss: 1.7197 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1050/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.1708 - acc: 0.5792 - val_loss: 1.7242 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1051/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.1523 - acc: 0.5792 - val_loss: 1.7257 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1052/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2322 - acc: 0.5458 - val_loss: 1.7224 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1053/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 32us/step - loss: 1.2345 - acc: 0.5667 - val_loss: 1.7203 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1054/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 43us/step - loss: 1.1668 - acc: 0.5458 - val_loss: 1.7195 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1055/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.2469 - acc: 0.5375 - val_loss: 1.7170 - val_acc: 0.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1056/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 95us/step - loss: 1.1926 - acc: 0.5458 - val_loss: 1.7190 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1057/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.1878 - acc: 0.5417 - val_loss: 1.7183 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1058/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.1838 - acc: 0.5500 - val_loss: 1.7230 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1059/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.2313 - acc: 0.5375 - val_loss: 1.7165 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1060/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 123us/step - loss: 1.2189 - acc: 0.5750 - val_loss: 1.7220 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1061/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2155 - acc: 0.5458 - val_loss: 1.7222 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1062/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 120us/step - loss: 1.2197 - acc: 0.5500 - val_loss: 1.7233 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1063/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2492 - acc: 0.5292 - val_loss: 1.7236 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1064/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 97us/step - loss: 1.2373 - acc: 0.5458 - val_loss: 1.7261 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1065/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.1957 - acc: 0.5417 - val_loss: 1.7357 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1066/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.2045 - acc: 0.5750 - val_loss: 1.7272 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1067/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.1670 - acc: 0.5792 - val_loss: 1.7273 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1068/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2331 - acc: 0.5125 - val_loss: 1.7204 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1069/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.1495 - acc: 0.5542 - val_loss: 1.7279 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1070/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2217 - acc: 0.5375 - val_loss: 1.7295 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1071/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.2315 - acc: 0.5083 - val_loss: 1.7333 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1072/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.2500 - acc: 0.5250 - val_loss: 1.7268 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1073/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2090 - acc: 0.5542 - val_loss: 1.7211 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1074/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2218 - acc: 0.5417 - val_loss: 1.7281 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1075/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 1.2709 - acc: 0.5208 - val_loss: 1.7263 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1076/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.1869 - acc: 0.5500 - val_loss: 1.7315 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1077/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.2388 - acc: 0.5125 - val_loss: 1.7245 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1078/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2140 - acc: 0.5125 - val_loss: 1.7268 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1079/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2162 - acc: 0.5375 - val_loss: 1.7241 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1080/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2232 - acc: 0.5292 - val_loss: 1.7181 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1081/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 43us/step - loss: 1.2752 - acc: 0.5333 - val_loss: 1.7206 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1082/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 52us/step - loss: 1.1899 - acc: 0.5292 - val_loss: 1.7323 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1083/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.2249 - acc: 0.5458 - val_loss: 1.7296 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1084/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 30us/step - loss: 1.2445 - acc: 0.5667 - val_loss: 1.7297 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1085/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2092 - acc: 0.5333 - val_loss: 1.7236 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1086/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 62us/step - loss: 1.2652 - acc: 0.5375 - val_loss: 1.7183 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1087/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 122us/step - loss: 1.2064 - acc: 0.5833 - val_loss: 1.7211 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1088/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.2471 - acc: 0.5417 - val_loss: 1.7266 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1089/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 128us/step - loss: 1.2318 - acc: 0.5292 - val_loss: 1.7290 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1090/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 103us/step - loss: 1.2105 - acc: 0.5708 - val_loss: 1.7241 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1091/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.2870 - acc: 0.5208 - val_loss: 1.7202 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1092/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2682 - acc: 0.4875 - val_loss: 1.7267 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1093/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2131 - acc: 0.5417 - val_loss: 1.7278 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1094/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2413 - acc: 0.5167 - val_loss: 1.7234 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1095/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.1494 - acc: 0.5708 - val_loss: 1.7281 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1096/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 1.2416 - acc: 0.4958 - val_loss: 1.7196 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1097/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.1849 - acc: 0.5625 - val_loss: 1.7173 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1098/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.1381 - acc: 0.5875 - val_loss: 1.7251 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1099/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.1929 - acc: 0.5333 - val_loss: 1.7248 - val_acc: 0.4861\n",
      "\n",
      "Epoch 1100/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.2174 - acc: 0.5542 - val_loss: 1.7226 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1101/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.2733 - acc: 0.5333 - val_loss: 1.7305 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1102/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 86us/step - loss: 1.2072 - acc: 0.5667 - val_loss: 1.7291 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1103/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 108us/step - loss: 1.2174 - acc: 0.5417 - val_loss: 1.7354 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1104/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 113us/step - loss: 1.1860 - acc: 0.5667 - val_loss: 1.7242 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1105/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.1866 - acc: 0.5500 - val_loss: 1.7232 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1106/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.2404 - acc: 0.5208 - val_loss: 1.7260 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1107/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2492 - acc: 0.5208 - val_loss: 1.7253 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1108/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2407 - acc: 0.5458 - val_loss: 1.7281 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1109/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2814 - acc: 0.5208 - val_loss: 1.7319 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1110/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.2094 - acc: 0.5667 - val_loss: 1.7354 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1111/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2667 - acc: 0.4958 - val_loss: 1.7341 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1112/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2500 - acc: 0.5458 - val_loss: 1.7409 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1113/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 56us/step - loss: 1.2367 - acc: 0.5542 - val_loss: 1.7315 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1114/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 61us/step - loss: 1.1851 - acc: 0.5375 - val_loss: 1.7338 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1115/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 1.1854 - acc: 0.5375 - val_loss: 1.7394 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1116/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.2149 - acc: 0.5417 - val_loss: 1.7362 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1117/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.1789 - acc: 0.5333 - val_loss: 1.7299 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1118/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.2267 - acc: 0.5500 - val_loss: 1.7280 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1119/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 62us/step - loss: 1.1744 - acc: 0.5667 - val_loss: 1.7308 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1120/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 107us/step - loss: 1.1692 - acc: 0.5792 - val_loss: 1.7304 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1121/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 105us/step - loss: 1.2838 - acc: 0.5000 - val_loss: 1.7319 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1122/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.1861 - acc: 0.5667 - val_loss: 1.7322 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1123/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 132us/step - loss: 1.2687 - acc: 0.5250 - val_loss: 1.7385 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1124/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 104us/step - loss: 1.2082 - acc: 0.5417 - val_loss: 1.7316 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1125/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2491 - acc: 0.5500 - val_loss: 1.7287 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1126/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.1746 - acc: 0.5417 - val_loss: 1.7334 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1127/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 133us/step - loss: 1.1388 - acc: 0.5875 - val_loss: 1.7416 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1128/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.1932 - acc: 0.5625 - val_loss: 1.7378 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1129/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.2069 - acc: 0.5750 - val_loss: 1.7272 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1130/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2148 - acc: 0.5500 - val_loss: 1.7367 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1131/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2387 - acc: 0.5458 - val_loss: 1.7338 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1132/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.1810 - acc: 0.5917 - val_loss: 1.7365 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1133/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.2248 - acc: 0.5417 - val_loss: 1.7369 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1134/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 90us/step - loss: 1.2329 - acc: 0.5458 - val_loss: 1.7347 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1135/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.1571 - acc: 0.5750 - val_loss: 1.7344 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1136/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 72us/step - loss: 1.2152 - acc: 0.5417 - val_loss: 1.7330 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1137/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.1881 - acc: 0.5667 - val_loss: 1.7289 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1138/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.1662 - acc: 0.5458 - val_loss: 1.7352 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1139/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 71us/step - loss: 1.1935 - acc: 0.5667 - val_loss: 1.7370 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1140/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 70us/step - loss: 1.1992 - acc: 0.5542 - val_loss: 1.7306 - val_acc: 0.4722\n",
      "\n",
      "Epoch 1141/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.1823 - acc: 0.5375 - val_loss: 1.7349 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1142/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.2086 - acc: 0.5375 - val_loss: 1.7366 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1143/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.1793 - acc: 0.5667 - val_loss: 1.7315 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1144/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.2504 - acc: 0.4917 - val_loss: 1.7314 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1145/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 75us/step - loss: 1.1637 - acc: 0.5583 - val_loss: 1.7281 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1146/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 49us/step - loss: 1.1638 - acc: 0.5750 - val_loss: 1.7365 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1147/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2603 - acc: 0.5333 - val_loss: 1.7347 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1148/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 33us/step - loss: 1.2103 - acc: 0.5208 - val_loss: 1.7394 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1149/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 34us/step - loss: 1.1928 - acc: 0.5500 - val_loss: 1.7416 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1150/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 31us/step - loss: 1.1468 - acc: 0.5375 - val_loss: 1.7346 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1151/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 41us/step - loss: 1.1991 - acc: 0.5208 - val_loss: 1.7376 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1152/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 115us/step - loss: 1.2257 - acc: 0.5667 - val_loss: 1.7463 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1153/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.2269 - acc: 0.5083 - val_loss: 1.7415 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1154/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 118us/step - loss: 1.1829 - acc: 0.5708 - val_loss: 1.7395 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1155/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 88us/step - loss: 1.1952 - acc: 0.5625 - val_loss: 1.7381 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1156/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 127us/step - loss: 1.1699 - acc: 0.5667 - val_loss: 1.7408 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1157/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 94us/step - loss: 1.2062 - acc: 0.5125 - val_loss: 1.7423 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1158/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 116us/step - loss: 1.2117 - acc: 0.5458 - val_loss: 1.7495 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1159/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.1697 - acc: 0.5542 - val_loss: 1.7482 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1160/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.1791 - acc: 0.5417 - val_loss: 1.7524 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1161/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 102us/step - loss: 1.2492 - acc: 0.5250 - val_loss: 1.7486 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1162/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 128us/step - loss: 1.1958 - acc: 0.5667 - val_loss: 1.7403 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1163/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.1751 - acc: 0.5583 - val_loss: 1.7390 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1164/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 76us/step - loss: 1.2105 - acc: 0.5333 - val_loss: 1.7411 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1165/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 78us/step - loss: 1.2617 - acc: 0.5625 - val_loss: 1.7420 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1166/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.1976 - acc: 0.5542 - val_loss: 1.7433 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1167/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.1361 - acc: 0.5750 - val_loss: 1.7512 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1168/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2481 - acc: 0.5417 - val_loss: 1.7420 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1169/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 87us/step - loss: 1.2246 - acc: 0.5375 - val_loss: 1.7424 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1170/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 82us/step - loss: 1.1829 - acc: 0.5500 - val_loss: 1.7380 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1171/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.2399 - acc: 0.5500 - val_loss: 1.7380 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1172/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 79us/step - loss: 1.1256 - acc: 0.6125 - val_loss: 1.7390 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1173/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 77us/step - loss: 1.1887 - acc: 0.5250 - val_loss: 1.7387 - val_acc: 0.4583\n",
      "\n",
      "Epoch 1174/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 81us/step - loss: 1.2005 - acc: 0.5292 - val_loss: 1.7480 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1175/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 80us/step - loss: 1.1790 - acc: 0.5625 - val_loss: 1.7522 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1176/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 83us/step - loss: 1.2382 - acc: 0.5042 - val_loss: 1.7520 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1177/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.2136 - acc: 0.5375 - val_loss: 1.7501 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1178/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 47us/step - loss: 1.2277 - acc: 0.5333 - val_loss: 1.7552 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1179/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 39us/step - loss: 1.2828 - acc: 0.5292 - val_loss: 1.7473 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1180/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.1791 - acc: 0.5375 - val_loss: 1.7538 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1181/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 35us/step - loss: 1.2590 - acc: 0.5333 - val_loss: 1.7495 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1182/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 37us/step - loss: 1.1321 - acc: 0.5208 - val_loss: 1.7512 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1183/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 59us/step - loss: 1.2159 - acc: 0.5208 - val_loss: 1.7544 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1184/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.1996 - acc: 0.5500 - val_loss: 1.7614 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1185/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 93us/step - loss: 1.2346 - acc: 0.5500 - val_loss: 1.7583 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1186/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.2445 - acc: 0.5542 - val_loss: 1.7567 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1187/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 96us/step - loss: 1.2333 - acc: 0.5208 - val_loss: 1.7517 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1188/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 117us/step - loss: 1.2215 - acc: 0.5542 - val_loss: 1.7522 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1189/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 98us/step - loss: 1.2398 - acc: 0.5125 - val_loss: 1.7538 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1190/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 91us/step - loss: 1.2291 - acc: 0.5292 - val_loss: 1.7504 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1191/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 100us/step - loss: 1.1932 - acc: 0.5042 - val_loss: 1.7517 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1192/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 101us/step - loss: 1.1715 - acc: 0.5750 - val_loss: 1.7537 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1193/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 114us/step - loss: 1.2298 - acc: 0.5167 - val_loss: 1.7539 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1194/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 99us/step - loss: 1.2261 - acc: 0.5042 - val_loss: 1.7579 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1195/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.2135 - acc: 0.5458 - val_loss: 1.7548 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1196/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 85us/step - loss: 1.1624 - acc: 0.5500 - val_loss: 1.7575 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1197/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 73us/step - loss: 1.1936 - acc: 0.5292 - val_loss: 1.7497 - val_acc: 0.4444\n",
      "\n",
      "Epoch 1198/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 74us/step - loss: 1.2844 - acc: 0.5000 - val_loss: 1.7498 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1199/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 121us/step - loss: 1.1980 - acc: 0.5792 - val_loss: 1.7474 - val_acc: 0.4306\n",
      "\n",
      "Epoch 1200/1200\n",
      "240/240 [==============================]240/240 [==============================] - 0s 84us/step - loss: 1.1062 - acc: 0.6042 - val_loss: 1.7494 - val_acc: 0.4444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####VIJETH\n",
    "########## HYPER PARAMETERS\n",
    "batch_size = 512\n",
    "epochs = 1200\n",
    "optimizer = tf.keras.optimizers.Adadelta()\n",
    "keras.initializers.glorot_normal(seed=None)\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "########## MODEL ARCHITECTURE\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(28, activation='relu',kernel_initializer='orthogonal', input_shape=(100,)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dense(16, activation='relu'))#WAS removed \n",
    "model.add(tf.keras.layers.Dense(Class, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "\n",
    "# compile model for training\n",
    "model.compile(loss='kullback_leibler_divergence',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f340d5b9470>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.ylabel('Accuracy ------------->')\n",
    "plt.xlabel('Epochs -------------->')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3410ba8f28>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_loss'], label=\"Testing Loss\")\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.ylabel('Loss ------------->')\n",
    "plt.xlabel('Epochs -------------->')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TempName = str(now.day) +str(now.month)+ str(now.hour) + str(now.minute)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(FilePath + \"Runs/\" + RunFolder + \"/ModelsAndWeights/\"+ TempName +\"Predict_DNN_100FVfromResnet_8Class.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(FilePath + \"Runs/\" + RunFolder + \"/ModelsAndWeights/\"+ TempName +\"Predict_DNN_100FVfromResnet_8Class.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
